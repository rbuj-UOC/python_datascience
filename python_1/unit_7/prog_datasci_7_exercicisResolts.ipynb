{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">22.401 · Fonaments de Programació</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grau en Ciència de Dades Aplicada</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicació</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programació per a *Data Science*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unitat 7: Anàlisi de dades en Python\n",
    "------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest Notebook trobareu un conjunt d'exercicis per practicar. Aquests exercicis no puntuen per la PAC, però us recomanem que els intenteu resoldre com a part del procés d'aprenentatge. Trobareu exemples de possibles solucions als exercicis en el propi notebook, però és important que intenteu resoldre'ls vosaltres abans de consultar les solucions. Les solucions us permetran validar les vostres respostes, així com veure alternatives de resolució de les activitats. També us animem a preguntar qualsevol dubte que sorgeixi sobre la resolució de les activitats per a practicar en el fòrum de l'aula.\n",
    "\n",
    "----\n",
    "## Preguntes i exercicis per practicar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1\n",
    "\n",
    "Investiga i descriu el funcionament de l'mètode de cross-validation *Leave One Out*. Posa un exemple d'aplicació de l'algorisme per resoldre un problema d'anàlisi en l'àmbit de la salut. Recordeu que cal citar les referències consultades per respondre la pregunta, i que la resposta que proporcioneu ha de ser original (redactada per vosaltres mateixos, després d'haver llegit i entès les referències que considereu oportunes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hem d'evitar avaluar els models amb les mateixes dades que s'han utilitzat per a l'aprenentatge. De no fer-ho, podríem afavorir el problema del **sobre-ajust**. En què consisteix aquest problema i quines conseqüències pot tenir?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 1\n",
    "\n",
    "Carregueu el conjunt de dades Iris incorporat a la llibreria `sklearn`. Implementeu una funció, `describe_iris`, que retorni un diccionari amb la següent estructura:\n",
    "\n",
    "```\n",
    "{\n",
    "   \"categories\": [],\n",
    "   \"atributs\": [],\n",
    "   \"num_mostres\": 0\n",
    "}\n",
    "```\n",
    "*Categories* ha de ser una matriu amb el nom dels **targets** del *dataset*. *Atributs* ha de ser una matriu amb el nom dels **atributs** i finalment, *num_mostres* ha d'indicar el nombre **total de mostres** de l'dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 2\n",
    "\n",
    "Representeu gràficament en un *scatter plot* la longitud dels sèpals en funció de l'ample dels sèpals.\n",
    "Nota: per poder incloure accents en els textos de les etiquetes o del títol del plot, cal indicar explícitament que les cadenes de caràcters són unicode. Podeu fer-ho incloent una _u_ davant de les cometes que delimiten la cadena de caràcters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir les dades Iris en dos subconjunts, dades d'entrenament i test, en una proporció 70% entrenament i 30% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliqueu el classificador _KNeighborsClassifier_ per predir el tipus d'espècie d'iris utilitzant la longitud i ample dels pètals com a atributs i utilitzant 60% de les mostres per entrenament i 40% de les mostres per al test (podeu fer servir qualsevol partició de mostres d'entrenament i de test).\n",
    "\n",
    "Quin rendiment s'obté?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 5\n",
    "\n",
    "Apliqueu l'algorisme de _clustering KMeans_ tal com hem vist al Notebook de teoria, però aquesta vegada utilitzant els següents paràmetres:\n",
    "\n",
    "```\n",
    "Número de clústers: 10\n",
    "Mètode d'inicialització dels punts centrals: 'random'\n",
    "Nombre d'iteracions per a la selecció de punts centrals: 5\n",
    "Algoritme: 'elkan'\n",
    "```\n",
    "\n",
    "Visualitzeu gràficament el resultat. Si les dades fossin [disperses](https://en.wikipedia.org/wiki/Sparse_matrix), quina opció del paràmetre _alg_ de la funció _sklearn.cluster.KMeans_ hauríem d'utilitzar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En els següents exercicis farem servir el conjunt de dades del dataset `breast_cancer` de *sklearn*. Crea una taula amb els estadístics descriptius de totes les característiques dels tumors de la base de dades `breast_cancer` agrupats per tipus (benigne/maligne).\n",
    "\n",
    "Feu un test estadístic [ttest](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) per comparar l'error de la simetria (*symmetry error*) i finor (*mean smoothness*) dels tumors benignes amb les dels malignes. Donat el resultat obtingut, indica quines característiques podrien ser més rellevants per diagnosticar un tumor maligne.\n",
    "\n",
    "Nota: Consulta aquest [enllaç](http://www.conexionismo.com/leer_articulo.php?ref=prueba_t_de_student_para_la_comparacion_de_dos_muestras_independientes-j960497l) si vols ampliar coneixements sobre el test estadístic ttest. Per fer el test estadístic automàticament podeu utilitzar el mètode [ `ttest_ind`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) de *Scipy.stats*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representa mitjançant [boxplots](https://en.wikipedia.org/wiki/Boxplots) com varien la textura, l'àrea, la concavitat i la simetria dels tumors segons el tipus (*maligne/benigne*). Recorda ajustar els paràmetres de la visualització per facilitar la lectura i la interpretació de la gràfica.\n",
    "\n",
    "Nota: Crea un dataframe amb les dades de `diagnostics.data` i` diagnostics.target` per dibuixar els boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importem les llibreries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns  # llibreria opcional\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets \n",
    "\n",
    "# Importem el dataset\n",
    "diagnostics = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectiu d'un model de **regressió lineal** és trobar una relació entre una o més característiques (variables independents) i una variable objectiu contínua (variable dependent). Quan només fem servir una característica predictiva se l'anomena **Regressió Lineal univariada** i si hi ha múltiples predictors es diu **Regressió Lineal Múltiple**.\n",
    "\n",
    "Quan la variable dependent és una variable binària que conté dades codificades com 1 (sí, èxit, etc.) o 0 (no, fallada, etc.), com és el cas de l'dataset `breast_cancer`, haurem de fer servir una [regressió logística](https://ca.wikipedia.org/wiki/Regressi%C3%B3_log%C3%ADstica).\n",
    "\n",
    "Crea un model de regressió logística que estimi la probabilitat que un tumor sigui maligne donada la seva àrea i la seva textura. Mostra la [matriu de confusió](https://ca.wikipedia.org/wiki/Matriu_de_confusi%C3%B3) del model obtingut.\n",
    "\n",
    "Nota: Potser t'interessa explorar la funció [sklearn.metrics.confusion_matrix ()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **Multi-layer Perceptron (MLP)** és un algorisme d'aprenentatge supervisat que aprèn una funció mitjançant l'entrenament d'un model que associa n dimensions d'entrada (*predictors*) amb dimensions de sortida (*targets*). Tenint en compte un conjunt de funcions i un objectiu, pot aprendre un aproximador de funcions no lineals per classificació o regressió. És diferent de la regressió logística, ja que entre la capa d'entrada i la de sortida, pot haver-hi una o més capes no lineals, anomenades capes ocultes (_hidden layers_).\n",
    "\n",
    "Aplica un classificador basat en un MLP per predir el tipus de tumor utilitzant l'àrea, la textura, la simetria i la concavitat, com a atributs i utilitzant el 70% de les mostres d'entrenament i el 30% de test. Heu d'utilitzar la funció [sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "Utilitza tres nivells (*layers*) amb 30 neurones per nivell. Quin valor de precisió obtenim en un model basat en un MLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliqueu un classificador basat en un [arbre de decicisió](https://es.wikipedia.org/wiki/Árbol_de_decisión)\n",
    "d'un màxim de 3 nivells de profunditat per predir els tipus de tumor utilitzant l'àrea, la textura i la simetria com a atributs i utilitzant 60% de les mostres d'entrenament i el 40% de test. Heu d'utilitzar la funció [sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "Quin valor de precisió obtenim en un model basat en un arbre de decisió? Representa l'arbre de decisió i exporta-ho a un arxiu PDF. Explora l'arbre resultant al PDF i respon a la següent pregunta: Donades aquestes dades, com diagnosticaries a un pacient que presenta un tumor d'àrea 400, simetria 0.18, i un valor de textura de 19 punts?\n",
    "\n",
    "Nota: Potser la funció [tree](https://scikit-learn.org/stable/modules/tree.html) de _sklearn_ sigui d'utilitat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Solucions exercicis per practicar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1\n",
    "\n",
    "Investiga i descriu el funcionament de l'mètode de cross-validation *Leave One Out*. Posa un exemple d'aplicació de l'algorisme per resoldre un problema d'anàlisi en l'àmbit de la salut. Recordeu que cal citar les referències consultades per respondre la pregunta, i que la resposta que proporcioneu ha de ser original (redactada per vosaltres mateixos, després d'haver llegit i entès les referències que considereu oportunes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta\n",
    "\n",
    "La validació creuada *Leave One Out* és essencialment una estimació del rendiment de generalització d'un model entrenat amb $𝑛 - 1$ mostres de dades, que generalment és una estimació lleugerament pessimista del rendiment d'un model entrenat en $𝑛$ mostres. És millor pensar en la validació creuada com una forma d'estimar el rendiment de generalització dels models generats per un procediment particular, en lloc del model en si. Per exemple, imaginem que estem creant un model predictiu del tipus de melanoma (alt o baix risc) i tenim una mostra relativament petita (1000 observacions) que inclouen 3 paràmetres descriptius del melanoma i el seu nivell de risc (alt o baix). Podem ajustar el model usant 999 de les 1000 observacions per després avaluar el seu rendiment donada l'observació que hem deixat fora del set d'entrenament. En aquest cas, podem repetir aquest mètode fins a 999 vegades, per estimar un rendiment mitjà de el model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2\n",
    "\n",
    "Hem d'evitar avaluar els models amb les mateixes dades que s'han utilitzat per a l'aprenentatge. De no fer-ho, podríem afavorir el problema del **sobre-ajust**. En què consisteix aquest problema i quines conseqüències pot tenir?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta\n",
    "\n",
    "L'excés d'ajust d'un model és un error de modelatge que es produeix quan una funció s'ajusta massa a un conjunt limitat de punts de dades. Per tant, només suposa un problema en els models d'aprenentatge supervisat. Una de les conseqüències de el sobre-ajust és que el model pren una forma massa complexa per explicar la idiosincràsia a les dades objecte d'estudi i difícilment generalitza a noves mostres de dades. La **generalització** és un terme utilitzat per descriure la capacitat del model de reaccionar davant les noves dades. És a dir, després de ser entrenat en un entrenament, un model pot digerir dades noves i fer prediccions precises. La capacitat del model per generalitzar és essencial per a l'èxit d'un model. Si un model s'ha format massa bé sobre dades d'entrenament, no podrà generalitzar-se. Farà prediccions inexactes quan es donin noves dades, i farà que el model sigui inútil encara que sigui capaç de fer prediccions precises per a les dades d'entrenament. D'això es diu sobre-ajust (*overfitting*).\n",
    "\n",
    "Un dels mètodes més utilitzats per avaluar el problema del sobre-ajust es diu **cross-validation**. És un model de validació de models per avaluar com es generalitzen els resultats a un conjunt de dades independent. S'utilitza principalment quant l'objectiu és la predicció i es vol estimar amb exactitud com es comportarà un model predictiu a la pràctica. Quant fem **cross-validation**, destinarem una part de les dades a fer l'entrenament de el model i l'altra part la reservarem per avaluar el rendiment del model après.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 1\n",
    "\n",
    "Carregueu el conjunt de dades Iris incorporat a la llibreria `sklearn`. Implementeu una funció, `describe_iris`, que retorni un diccionari amb la següent estructura:\n",
    "\n",
    "```\n",
    "{\n",
    "   \"categories\": [],\n",
    "   \"atributs\": [],\n",
    "   \"num_mostres\": 0\n",
    "}\n",
    "```\n",
    "*Categories* ha de ser una matriu amb el nom dels **targets** del *dataset*. *Atributs* ha de ser una matriu amb el nom dels **atributs** i finalment, *num_mostres* ha d'indicar el nombre **total de mostres** de l'dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "#Carreguem el dataset de l'iris\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "def describe_iris():\n",
    "    #Inicialitzem el diccionari\n",
    "    diccionari = {}\n",
    "    #Assignem a cada atribut el valor corresponent basant-se el dataset Iris\n",
    "    diccionari[\"categorias\"] = iris.target_names\n",
    "    diccionari[\"atributos\"] = iris.feature_names\n",
    "    diccionari[\"num_muestras\"] = len(iris.data)\n",
    "    \n",
    "    return diccionari\n",
    "\n",
    "print (describe_iris())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representeu gràficament en un *scatter plot* la longitud dels sèpals en funció de l'ample dels sèpals.\n",
    "Nota: per poder incloure accents en els textos de les etiquetes o del títol del plot, cal indicar explícitament que les cadenes de caràcters són unicode. Podeu fer-ho incloent una _u_ davant de les cometes que delimiten la cadena de caràcters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#Importem les llibreries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# Importem el dataset\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "L_sep = iris.data[:,0]\n",
    "\n",
    "W_sep= iris.data[:,1]\n",
    "\n",
    "Y = iris.target\n",
    "\n",
    "# Creem la figura\n",
    "\n",
    "plt.figure(1, figsize=(8,6))\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.scatter(L_sep,W_sep,c=Y)\n",
    "plt.xlabel(u'Longitud Sépalo')\n",
    "plt.ylabel(u'Ancho Sépalo')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir les dades Iris en dos subconjunts, dades d'entrenament i test, en una proporció 70% entrenament i 30% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "# Dividim les dades en dades d'entrenament (70%) i de test (30%) mitjançant la funció train_test_split\n",
    "\n",
    "train,test = train_test_split(iris.data, test_size=0.3)\n",
    "\n",
    "# L'atribut test_size = 0.3 divideix les dades en una proporció de 70% i 30%. entrenament = 70% i test = 30%.\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 4\n",
    "\n",
    "Apliqueu el classificador _KNeighborsClassifier_ per predir el tipus d'espècie d'iris utilitzant la longitud i ample dels pètals com a atributs i utilitzant 60% de les mostres per entrenament i 40% de les mostres per al test (podeu fer servir qualsevol partició de mostres d'entrenament i de test).\n",
    "\n",
    "Quin rendiment s'obté?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets\n",
    "\n",
    "#Carreguen les dades\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(iris.data)\n",
    "\n",
    "# Assignem categoria a cadascuna de les espècies\n",
    "iris_df['Species'] = iris.target\n",
    "iris_df.loc[(iris_df.Species == 0),\"Species\"] = iris.target_names[0]\n",
    "iris_df.loc[(iris_df.Species == 1),\"Species\"] = iris.target_names[1]\n",
    "iris_df.loc[(iris_df.Species == 2),\"Species\"] = iris.target_names[2]\n",
    "\n",
    "iris_df.columns = ['SepalLength', 'SepalWitdh', 'PetalLength','PetalWitdh','Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resposta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Dividim les dades en dades d'entrenament (60%) i de test (40%) mitjançant la funció train_test_split\n",
    "\n",
    "train,test = train_test_split(iris_df, test_size=0.4)\n",
    "\n",
    "# Creem el classificador \n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Entrenem el classificador\n",
    "knn.fit( train[['PetalLength','PetalWitdh']],train[['Species']])\n",
    "\n",
    "# Provem el classificador\n",
    "iris_predicted=knn.predict(test[['PetalLength','PetalWitdh']])\n",
    "\n",
    "# Mostrem els resultats de la predicció sobre el conjunt de test\n",
    "\n",
    "print (\"Accuracy: \\t\\t\" + str(knn.score(test[['PetalLength','PetalWitdh']],test[['Species']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 5\n",
    "\n",
    "Apliqueu l'algorisme de _clustering KMeans_ tal com hem vist al Notebook de teoria, però aquesta vegada utilitzant els següents paràmetres:\n",
    "\n",
    "```\n",
    "Número de clústers: 10\n",
    "Mètode d'inicialització dels punts centrals: 'random'\n",
    "Nombre d'iteracions per a la selecció de punts centrals: 5\n",
    "Algoritme: 'elkan'\n",
    "```\n",
    "\n",
    "Visualitzeu gràficament el resultat. Si les dades fossin [disperses](https://en.wikipedia.org/wiki/Sparse_matrix), quina opció del paràmetre _alg_ de la funció _sklearn.cluster.KMeans_ hauríem d'utilitzar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import cluster, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "\n",
    "# Consultem l'ajuda de K-means per veure com es defineixen els paràmetres\n",
    "?cluster.KMeans\n",
    "\n",
    "# Carreguem l'algoritme K-means i ajustem els paràmetres segons l'enunciat\n",
    "k_means = cluster.KMeans(n_clusters=10,init='random',n_init=5, algorithm='elkan')\n",
    "k_means.fit(X_iris)\n",
    "\n",
    "# Definim els paràmetres de la figura\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "ax.scatter(X_iris[:,[0]], X_iris[:,[1]], X_iris[:,[2]], c=k_means.labels_)\n",
    "ax.set_title(u\"Taxonomía de las 150 muestras utilizando K-means\")\n",
    "ax.set_xlabel(u\"Longitud del sépalo\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(u\"Ancho del sépalo\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(u\"Longitud del pétalo\")\n",
    "ax.w_zaxis.set_ticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si les dades fossin disperses, el paràmetre _algorithm_ hauria de ser 'full'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En els següents exercicis farem servir el conjunt de dades del dataset `breast_cancer` de *sklearn*. Crea una taula amb els estadístics descriptius de totes les característiques dels tumors de la base de dades `breast_cancer` agrupats per tipus (benigne/maligne).\n",
    "\n",
    "Feu un test estadístic [ttest](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) per comparar l'error de la simetria (*symmetry error*) i finor (*mean smoothness*) dels tumors benignes amb les dels malignes. Donat el resultat obtingut, indica quines característiques podrien ser més rellevants per diagnosticar un tumor maligne.\n",
    "\n",
    "Nota: Consulta aquest [enllaç](http://www.conexionismo.com/leer_articulo.php?ref=prueba_t_de_student_para_la_comparacion_de_dos_muestras_independientes-j960497l) si vols ampliar coneixements sobre el test estadístic ttest. Per fer el test estadístic automàticament podeu utilitzar el mètode [ `ttest_ind`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) de *Scipy.stats*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta\n",
    "\n",
    "# Importem les llibreries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets \n",
    "import scipy.stats as stats\n",
    "\n",
    "# Importem el dataset\n",
    "diagnostics = datasets.load_breast_cancer()\n",
    "\n",
    "# Els transformem en un dataframe\n",
    "diagnostics_df = pd.DataFrame(diagnostics.data)\n",
    "\n",
    "# Nombrem les columnes de las variables\n",
    "diagnostics_df.columns = diagnostics['feature_names']\n",
    "\n",
    "# Afegim la columna Type amb el resultat de la diagnosi (benigne / maligne)\n",
    "diagnostics_df['Type'] = diagnostics.target\n",
    "\n",
    "# Mostrem per pantalla els paràmetres descriptius de la mostra\n",
    "diagnostics_df.groupby('Type').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realitzem un test estadístic per a cada variable comparant els tumors benignes (tipus 0) i malignes (tipus 1).\n",
    "# Executem 1 prova t de student per a mostres independents ja que cada registre correspon amb un pacient diferent.\n",
    "t1, p1 = stats.ttest_ind(diagnostics_df.query(\"Type==0\")['mean smoothness'],diagnostics_df.query(\"Type==1\")['mean smoothness'])\n",
    "print(\"Análisis de la tersura. Estadístico t= \" + str(t1) + \", p-val = \" + str(p1) )\n",
    "t2, p2 = stats.ttest_ind(diagnostics_df.query(\"Type==0\")['symmetry error'],diagnostics_df.query(\"Type==1\")['symmetry error'])\n",
    "print(\"Análisis del error de la simetría. Estadístico t= \" + str(t2) + \", p-val = \" + str(p2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta\n",
    "Preferirem la variable finor com diferenciadora dels tumors benignes i malignes ja que el test suggereix que les dues mostres de llisor comparades provenen de poblacions diferents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representa mitjançant [boxplots](https://en.wikipedia.org/wiki/Boxplots) com varien la textura, l'àrea, la concavitat i la simetria dels tumors segons el tipus (*maligne/benigne*). Recorda ajustar els paràmetres de la visualització per facilitar la lectura i la interpretació de la gràfica.\n",
    "\n",
    "Nota: Crea un dataframe amb les dades de `diagnostics.data` i` diagnostics.target` per dibuixar els boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importem les llibreries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns  # llibreria opcional\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets \n",
    "\n",
    "# Importem el dataset\n",
    "diagnostics = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resposta\n",
    "diagnostics_df = pd.DataFrame(diagnostics.data)\n",
    "\n",
    "# Assignem una categoria a cada tumor\n",
    "diagnostics_df.columns = diagnostics['feature_names']\n",
    "diagnostics_df['Type'] = diagnostics.target\n",
    "diagnostics_df.loc[(diagnostics_df.Type == 0),\"Type\"] = diagnostics.target_names[0]\n",
    "diagnostics_df.loc[(diagnostics_df.Type == 1),\"Type\"] = diagnostics.target_names[1]\n",
    "\n",
    "# Definim paràmetres de la figura\n",
    "label=['maligno','benigno']\n",
    "pos=[1,2]\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "\n",
    "# Dibuixem cadascun dels gràfics\n",
    "vplot1=axes[0,0].boxplot([np.array(diagnostics_df['mean texture'][diagnostics_df.Type == 'malignant']),\n",
    "                           np.array(diagnostics_df['mean texture'][diagnostics_df.Type == 'benign'],\n",
    "                                   )],vert=False)\n",
    "axes[0,0].set_xlabel('texture')\n",
    "axes[0,0].set_ylabel('Type')\n",
    "axes[0,0].set_yticks(pos)\n",
    "axes[0,0].set_yticklabels(label)\n",
    "\n",
    "vplot2=axes[0,1].boxplot([np.array(diagnostics_df['mean area'][diagnostics_df.Type == 'malignant']),\n",
    "                           np.array(diagnostics_df['mean area'][diagnostics_df.Type == 'benign'],\n",
    "                                   )],vert=False)\n",
    "axes[0,1].set_xlabel('area')\n",
    "axes[0,1].set_ylabel('Type')\n",
    "axes[0,1].set_yticks(pos)\n",
    "axes[0,1].set_yticklabels(label)\n",
    "\n",
    "vplot3=axes[1,0].boxplot([np.array(diagnostics_df['mean concavity'][diagnostics_df.Type == 'malignant']),\n",
    "                           np.array(diagnostics_df['mean concavity'][diagnostics_df.Type == 'benign'],\n",
    "                                   )],vert=False)\n",
    "axes[1,0].set_xlabel('concavity')\n",
    "axes[1,0].set_ylabel('Type')\n",
    "axes[1,0].set_yticks(pos)\n",
    "axes[1,0].set_yticklabels(label)\n",
    "\n",
    "vplot4=axes[1,1].boxplot([np.array(diagnostics_df['mean symmetry'][diagnostics_df.Type == 'malignant']),\n",
    "                           np.array(diagnostics_df['mean symmetry'][diagnostics_df.Type == 'benign'],\n",
    "                                   )],vert=False)\n",
    "axes[1,1].set_xlabel('symmetry')\n",
    "axes[1,1].set_ylabel('Type')\n",
    "axes[1,1].set_yticks(pos)\n",
    "axes[1,1].set_yticklabels(label)\n",
    "colors = ['forestgreen', 'darkorange']\n",
    "\n",
    "\n",
    "# Assignem color a cada un dels cossos del boxplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opció 2: Una altra forma de fer l'exercici és mitjançant la llibreria\n",
    "# Seaborn, que veurem en la propera unitat\n",
    "\n",
    "# Importem les llibreries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets\n",
    "\n",
    "# Importem el dataset\n",
    "diagnostics = datasets.load_breast_cancer()\n",
    "diagnostics_df = pd.DataFrame(diagnostics.data)\n",
    "\n",
    "# Assignem una categoria a cada tumor\n",
    "diagnostics_df.columns = diagnostics['feature_names']\n",
    "diagnostics_df['Type'] = diagnostics.target\n",
    "diagnostics_df.loc[(diagnostics_df.Type == 0),\"Type\"] = diagnostics.target_names[0]\n",
    "diagnostics_df.loc[(diagnostics_df.Type == 1),\"Type\"] = diagnostics.target_names[1]\n",
    "\n",
    "# Dibuixem cadascuna de les gràfiques\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(x=diagnostics_df['mean texture'],y=diagnostics_df.Type)\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(x=diagnostics_df['mean area'],y=diagnostics_df.Type)\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxplot(x=diagnostics_df['mean concavity'],y=diagnostics_df.Type)\n",
    "plt.subplot(2,2,4)\n",
    "sns.boxplot(x=diagnostics_df['mean symmetry'],y=diagnostics_df.Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectiu d'un model de **regressió lineal** és trobar una relació entre una o més característiques (variables independents) i una variable objectiu contínua (variable dependent). Quan només fem servir una característica predictiva se l'anomena **Regressió Lineal univariada** i si hi ha múltiples predictors es diu **Regressió Lineal Múltiple**.\n",
    "\n",
    "Quan la variable dependent és una variable binària que conté dades codificades com 1 (sí, èxit, etc.) o 0 (no, fallada, etc.), com és el cas de l'dataset `breast_cancer`, haurem de fer servir una [regressió logística](https://ca.wikipedia.org/wiki/Regressi%C3%B3_log%C3%ADstica).\n",
    "\n",
    "Crea un model de regressió logística que estimi la probabilitat que un tumor sigui maligne donada la seva àrea i la seva textura. Mostra la [matriu de confusió](https://ca.wikipedia.org/wiki/Matriu_de_confusi%C3%B3) del model obtingut.\n",
    "\n",
    "Nota: Potser t'interessa explorar la funció [sklearn.metrics.confusion_matrix ()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = diagnostics_df[['mean texture','mean area']]\n",
    "y = diagnostics_df['Type']\n",
    "\n",
    "# Dividim les dades en dades d'entrenament (60%) i de test (40%) mitjançant la funció train_test_split\n",
    "train,test = train_test_split(diagnostics_df, test_size=0.4)\n",
    "train_X = train[['mean texture','mean area']]\n",
    "train_y = train['Type']\n",
    "test_X = test[['mean texture','mean area']]\n",
    "test_y = test['Type']\n",
    "\n",
    "# Apliquem la regressió\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(train_X, train_y)\n",
    "clf.score(test_X,test_y)\n",
    "\n",
    "# Predim el tipus de càncer atesos els predictors textura i Àrea\n",
    "predicted = clf.predict( diagnostics_df[['mean texture','mean area']].values )\n",
    "real      = diagnostics_df['Type'].values\n",
    "\n",
    "# Representem la matriu de confusió\n",
    "import matplotlib.pyplot as plt \n",
    "result_cofusion_mat = []\n",
    "for real_c in ['benign','malignant']:\n",
    "    tmp = []\n",
    "    for pred_c in ['benign','malignant']:\n",
    "        # Dividim per el nom total de casos per calcular la proporció de:\n",
    "        # Vertaders positius, vertaders negatius, falsos positius, i falsos negatius\n",
    "        tmp.append( np.where(np.logical_and(predicted==pred_c, real==real_c))[0].size /np.where(real==real_c)[0].size)\n",
    "    result_cofusion_mat.append(tmp)\n",
    "    \n",
    "plt.matshow(result_cofusion_mat)\n",
    "plt.xticks( [0,1], ['Pred. benign','Pred. malignant'] )\n",
    "plt.yticks( [0,1], ['True benign','True malignant'] )\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **Multi-layer Perceptron (MLP)** és un algorisme d'aprenentatge supervisat que aprèn una funció mitjançant l'entrenament d'un model que associa n dimensions d'entrada (*predictors*) amb dimensions de sortida (*targets*). Tenint en compte un conjunt de funcions i un objectiu, pot aprendre un aproximador de funcions no lineals per classificació o regressió. És diferent de la regressió logística, ja que entre la capa d'entrada i la de sortida, pot haver-hi una o més capes no lineals, anomenades capes ocultes (_hidden layers_).\n",
    "\n",
    "Aplica un classificador basat en un MLP per predir el tipus de tumor utilitzant l'àrea, la textura, la simetria i la concavitat, com a atributs i utilitzant el 70% de les mostres d'entrenament i el 30% de test. Heu d'utilitzar la funció [sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "Utilitza tres nivells (*layers*) amb 30 neurones per nivell. Quin valor de precisió obtenim en un model basat en un MLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Dividim les dades en dades d'entrenament (70%) i de test (30%) mitjançant la funció train_test_split\n",
    "train,test = train_test_split(diagnostics_df, test_size=0.3)\n",
    "train_X = train[['mean texture','mean area','mean symmetry','mean concavity']]\n",
    "train_y = train['Type']\n",
    "test_X = test[['mean texture','mean area','mean symmetry','mean concavity']]\n",
    "test_y = test['Type']\n",
    "\n",
    "# Apliquem el MLP\n",
    "clf = MLPClassifier(hidden_layer_sizes=(3, 30), max_iter=1000)\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "# Mostrem la precisió\n",
    "score = clf.score(test_X, test_y)\n",
    "print(\"El model té un \" + str(np.around(score,2)*100) + '% de precisió en predir el tipus de tumor.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliqueu un classificador basat en un [arbre de decicisió](https://es.wikipedia.org/wiki/Árbol_de_decisión)\n",
    "d'un màxim de 3 nivells de profunditat per predir els tipus de tumor utilitzant l'àrea, la textura i la simetria com a atributs i utilitzant 60% de les mostres d'entrenament i el 40% de test. Heu d'utilitzar la funció [sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "Quin valor de precisió obtenim en un model basat en un arbre de decisió? Representa l'arbre de decisió i exporta-ho a un arxiu PDF. Explora l'arbre resultant al PDF i respon a la següent pregunta: Donades aquestes dades, com diagnosticaries a un pacient que presenta un tumor d'àrea 400, simetria 0.18, i un valor de textura de 19 punts?\n",
    "\n",
    "Nota: Potser la funció [tree](https://scikit-learn.org/stable/modules/tree.html) de _sklearn_ sigui d'utilitat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "# Dividim les dades en dades d'entrenament (60%) i de test (40%) mitjançant la funció train_test_split\n",
    "train,test = train_test_split(diagnostics_df, test_size=0.40)\n",
    "\n",
    "# Creem el classificador \n",
    "dtree = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Entrenem el classificador\n",
    "fit = dtree.fit(train[['mean area','mean symmetry', 'mean texture']],train[['Type']])\n",
    "\n",
    "# Avaluem la precisió del classificador\n",
    "score = dtree.score(test[['mean area','mean symmetry', 'mean texture']],test[['Type']])\n",
    "print(\"El model té un \" + str(np.around(score,2)*100) + '% de precisió en predir el tipus de tumor.' )\n",
    "\n",
    "# Mostrem l'arbre de decisió i el exportem a un arxiu PDF\n",
    "fig = plt.figure(figsize=(20,20), facecolor='w')\n",
    "tree.plot_tree(fit, filled=True, feature_names=['mean area','mean symmetry', 'mean texture'], class_names=['benigno','maligno']);\n",
    "plt.savefig('tree.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta\n",
    "\n",
    "Classificarem el tumor com benigne (corresponent amb el primer full de l'arbre) amb una probabilitat d'error (impuresa de Gini) bastant baixa."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
