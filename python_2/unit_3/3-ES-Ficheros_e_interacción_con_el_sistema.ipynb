{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">22.503 · Programación para la ciencia de datos</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grado en Ciencia de Datos Aplicada</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programación para la ciencia de datos\n",
    "============================\n",
    "\n",
    "--- \n",
    "\n",
    "Unidad 3: Archivos e interacción con el sistema\n",
    "-----------------------------------------------------\n",
    "\n",
    "---\n",
    "\n",
    "### Instrucciones de uso\n",
    "\n",
    "Este documento es un notebook interactivo que intercala explicaciones más bien teóricas de conceptos de programación con fragmentos de código ejecutables. Para aprovechar las ventajas que aporta este formato, se recomienda, en primer lugar, leer las explicaciones y el código que os proporcionamos. De esta manera tendréis un primer contacto con los conceptos que se exponen. Ahora bien, **¡la lectura es solo el principio!** Una vez que hayáis leído el contenido proporcionado, no olvidéis ejecutar el código proporcionado y modificarlo para crear variantes, que os permitan comprobar que habéis entendido su funcionalidad y explorar los detalles de la implementación. Por último, se recomienda también consultar la documentación enlazada para explorar con más profundidad las funcionalidades de los módulos presentados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activamos las alertas de estilo\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "En esta unidad veremos cómo podemos interactuar con el sistema operativo utilizando Python.\n",
    "\n",
    "En primer lugar, nos centraremos en los ficheros: veremos cómo se puede leer el contenido de un archivo en Python, cómo se pueden crear nuevos archivos y escribir su contenido, cómo podemos realizar otras tareas básicas sobre ficheros (como cambiar el nombre de un fichero, borrarlo, o crear carpetas), y algunos otros detalles a tener en cuenta a la hora de trabajar con archivos desde Python.\n",
    "\n",
    "Seguidamente, se explican las nociones básicas para trabajar con archivos comprimidos desde Python, explicando cómo leer y crear archivos comprimidos, y otras tareas básicas como listar el contenido de un archivo comprimido.\n",
    "\n",
    "A continuación se presentan las funciones de carga de datos de más alto nivel, que permiten cargar conjuntos de datos desde ficheros sin necesidad de leer y procesar manualmente su contenido.\n",
    "\n",
    "Después, veremos una alternativa para conseguir persistencia de datos de nuestras aplicaciones: la serialización con `pickle`.\n",
    "\n",
    "Ya para terminar, explicaremos cómo podemos interactuar con una base de datos SQL desde nuestro código Python, y cómo podemos ejecutar otros programas también desde nuestro código.\n",
    "\n",
    "A continuación se incluye la tabla de contenidos, que podéis utilizar para navegar por el documento:\n",
    "\n",
    "<ul style=\"list-style-type:none\">\n",
    "<li> <a href='#1.--Ficheros-(con-el-módulo-os)'> 1. Ficheros (con el módulo os) </a> </li>\n",
    "    <ul style=\"list-style-type:none\">\n",
    "<li> <a href='#1.1.--Lectura-y-escritura-de-ficheros'> 1.1. Lectura y escritura de ficheros </a> </li>\n",
    "        <ul style=\"list-style-type:none\">\n",
    "<li> <a href='#1.1.1.--El-path'> 1.1.1. El path </a> </li>\n",
    "<li> <a href='#1.1.2.--El-modo'> 1.1.2. El modo </a> </li>\n",
    "<li> <a href=\"#1.1.3.--Otros-detalles-en-la-apertura-de-ficheros\"> 1.1.3. Otros detalles en la apertura de ficheros </a> </li>\n",
    "<li> <a href='#1.1.4.--Lectura-de-ficheros-grandes'> 1.1.4. Lectura de ficheros grandes </a> </li>\n",
    "        </ul>\n",
    "<li> <a href='#1.2.--Creación-de-carpetas'> 1.2. Creación de carpetas </a> </li>\n",
    "<li> <a href='#1.3.--Borrar-y-renombrar'> 1.3. Borrar y renombrar </a> </li>\n",
    "<li> <a href='#1.4.--Funciones-auxiliares-de-paths'> 1.4. Funciones auxiliares de paths </a> </li>\n",
    "<li> <a href='#1.5.--Listado-de-directorios'> 1.5. Listado de directorios </a> </li>\n",
    "<li> <a href='#1.6.--Patrones-de-Unix-shell'> 1.6. Patrones de Unix shell </a> </li>\n",
    "<li> <a href='#1.7.--Obtención-de-metadatos-de-los-ficheros'> 1.7. Obtención de metadatos de los ficheros </a> </li>\n",
    "    </ul>\n",
    "<li> <a href='#2.--Trabajo-con-ficheros-comprimidos'> 2. Trabajo con archivos comprimidos </a> </li>\n",
    "    <ul style=\"list-style-type:none\">\n",
    "<li> <a href='#2.1.--Lectura-y-escritura-de-ficheros-comprimidos'> 2.1. Lectura y escritura de ficheros comprimidos </a> </li>\n",
    "        <ul style=\"list-style-type:none\">\n",
    "<li> <a href='#2.1.1.--El-path-y-el-modo'> 2.1.1. El path y el modo </a> </li>\n",
    "<li> <a href=\"#2.1.2.--Otros-detalles-en-la-apertura-de-ficheros\"> 2.1.2. Otros detalles en la apertura de archivos </a> </li>\n",
    "<li> <a href=\"#2.1.3.--Lectura-de-ficheros-grandes\"> 2.1.3. Lectura de ficheros grandes </a> </li>\n",
    "        </ul>\n",
    "<li> <a href='#2.2.--Borrar,-renombrar-y-crear-carpetas'> 2.2. Borrar, renombrar y crear carpetas </a> </li>\n",
    "<li> <a href='#2.3.--Funciones-auxiliares-de-paths,-listados-y-metadatos'> 2.3. Funciones auxiliares de paths, listados y metadatos </a> </li>\n",
    "    </ul>\n",
    "<li> <a href='#3.--Lectura-y-escritura-de-ficheros-con-pandas'> 3. Lectura y escritura de ficheros con pandas </a> </li>\n",
    "<li> <a href='#4.--Serialización-de-datos'> 4. Serialización de datos </a> </li>\n",
    "    <ul style=\"list-style-type:none\">\n",
    "<li> <a href='#4.1--Serialización-de-datos-con-pickle'> 4.1. Serialización de datos con pickle </a> </li>\n",
    "<li> <a href='#4.2--Consideraciones-sobre-la-serialización-de-datos'> 4.2. Consideraciones sobre la serialización de datos </a> </li>\n",
    "    </ul>\n",
    "<li> <a href='#5.--Interacción-con-bases-de-datos'> 5. Interacción con bases de datos </a> </li>\n",
    "<li> <a href='#6.--Interacción-con-el-sistema-operativo'> 6. Interacción con el sistema operativo </a> </li>\n",
    "<li> <a href=\"#7.--Ejercicios-para-practicar\"> 7. Ejercicios para practicar </a> </li>\n",
    "    <ul style=\"list-style-type:none\">\n",
    "<li> <a href='#7.1.--Soluciones-a-los-ejercicios-para-practicar'> 7.1. Soluciones a los ejercicios para practicar </a> </li>\n",
    "    </ul>\n",
    "<li> <a href=\"#8.--Bibliografía\"> 8. Bibliografía </a> </li>\n",
    "    <ul style=\"list-style-type:none\">\n",
    "<li> <a href='#8.1.--Bibliografía-básica'> 8.1. Bibliografía básica </a> </li>\n",
    "<li> <a href='#8.2.--Bibliografía-adicional---Ampliación-de-conocimientos'> 8.2. Bibliografía adicional </a> </li>\n",
    "    </ul>  \n",
    "</ul>\n",
    "\n",
    "**Nota importante:** La ejecución de este notebook modifica los archivos de la carpeta de la unidad 3 (se crean nuevos ficheros, se borran otros, se modifica el contenido de los existentes, etc.). Las explicaciones que se incluyen en este notebook concuerdan con la ejecución lineal de las celdas del notebook la primera vez que se hace esta ejecución. A partir de entonces, si volvéis a ejecutar el notebook (o si alteráis el orden de ejecución de las celdas para hacer pruebas), las explicaciones pueden no coincidir exactamente con los resultados que se producirán de la ejecución, ya que el estado inicial de los archivos no es el mismo.\n",
    "\n",
    "Si queréis restaurar el estado inicial de todos los archivos que se alteran al ejecutar este notebook (para poder volver a ejecutar el notebook tal como estaba inicialmente), abrid una consola y ejecutad:\n",
    "\n",
    "```\n",
    "cd ~/prog_datasci_2/resources/unit_3 && rm -rf files_folder file_2.txt mem_data; unzip files_folder.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1.- Ficheros (con el módulo `os`)\n",
    "\n",
    "El módulo [`os`](https://docs.python.org/3.8/library/os.html) provee de funciones para interactuar con el sistema operativo. Entre otras, incluye funciones para manipular archivos.\n",
    "\n",
    "## 1.1.- Lectura y escritura de ficheros\n",
    "\n",
    "Para leer y/o escribir un archivo, lo primero que hay que hacer es abrirlo, especificando su *path* y el modo de apertura. Con el archivo abierto, podremos operar sobre él (ya sea leerlo o escribir en él). Finalmente, cuando hayamos finalizado la operación, habrá que cerrarlo, para liberar los recursos.\n",
    "\n",
    "**¡Es importante cerrar los ficheros que abrimos!** Más allá de ser una buena práctica, hay que tener en cuenta que ciertos cambios en los ficheros pueden no ser visibles hasta que se cierren los archivos (ya que el sistema operativo implementa *buffers* para optimizar la gestión). Además, aunque Python tiene un sistema automático de cierre de recursos, puede que este falle, dejando los archivos abiertos y, en consecuencia, consumiendo memoria RAM (y, por lo tanto, impactando negativamente en el rendimiento del programa), y contribuyendo a los contadores que controlan el número máximo de archivos abiertos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el módulo os\n",
    "import os\n",
    "\n",
    "# Abrimos el archivo test_file.txt para escritura\n",
    "out = open('files_folder/test_file.txt', 'w')\n",
    "# Escribimos la palabra 'test' en el archivo\n",
    "out.write(\"test\")\n",
    "# Cerramos el archivo\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el flujo tradicional de trabajo con ficheros: se abre el archivo especificando el *path* y el modo, se opera con el archivo (en este caso, hemos escrito la palabra 'test') y, finalmente, se cierra el archivo. Después de ejecutar la celda anterior, abrid el archivo (con vuestro navegador de archivos del sistema operativo), y comprobad que efectivamente contiene la palabra 'test'.\n",
    "\n",
    "Esta estructura de trabajo con archivos obliga al programador a recordar cerrar el archivo manualmente una vez ha terminado de operar con él. Como alternativa a esta estructura tradicional, Python permite utilizar la sentencia `with`, que crea un contexto en el que el archivo está abierto, y libera así al programador de la tarea de recordar cerrar el archivo. Así, cuando la ejecución sale del contexto, Python cerrará automáticamente el archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo test_file_2.txt para escritura\n",
    "with open('files_folder/test_file_2.txt', 'w') as out:\n",
    "    # Escribimos 'another test' en el archivo\n",
    "    out.write(\"another test\")\n",
    "\n",
    "# Intentamos escribir más contenido en el mismo archivo\n",
    "try:\n",
    "    out.write(\"fail\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijaos como, si intentamos operar con el archivo fuera del contexto del `with`, se genera una excepción, ya que el archivo ya está cerrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1.- El path\n",
    "\n",
    "El primer argumento que recibe la función [`open`](https://docs.python.org/3/library/functions.html#open) (y el único que es obligatorio) es el *path*. El *path* puede ser absoluto o relativo al directorio donde se está ejecutando el código.\n",
    "\n",
    "Indicaremos que el *path* es **absoluto** iniciándolo con una barra, `/` (que indica el directorio raíz).\n",
    "\n",
    "En cambio, si el *path* comienza con un carácter, éste será **relativo** al directorio donde se ejecuta el código. Así, en los dos ejemplos anteriores, los *paths* `test_file.txt` y `test_file_2.txt` eran relativos al directorio de ejecución, indicando que los archivos se encontraban directamente en el propio directorio.\n",
    "\n",
    "Del mismo modo que en el sistema operativo, podemos utilizar `.` y` ..` para referirnos, respectivamente, al directorio actual y al superior al actual en *paths* relativos. Especificaremos el *path* utilizando también barras `/` después de cada nombre de directorio.\n",
    "\n",
    "\n",
    "### 1.1.2.- El modo\n",
    "\n",
    "En relación con el modo de apertura, Python reconoce los siguientes modificadores, que se pueden combinar entre ellos para especificar cómo y con qué finalidad se abre el fichero:\n",
    "\n",
    "* `r`, modo de lectura (del inglés, _**r**eading_).\n",
    "* `w`, modo de escritura (del inglés, _**w**riting_), sobrescribe el contenido del archivo si éste ya existe, o bien crea el archivo si no existe.\n",
    "* `x`, modo de creación e**x**clusiva.\n",
    "* `a`, modo de escritura, escribe al final del archivo, después del contenido ya existente en el archivo (del inglés, _**a**ppend_), o bien crea el archivo si no existe.\n",
    "* `b`, modo **b**inario.\n",
    "* `t`, modo de **t**exto (modo predeterminado).\n",
    "* `+`, modo de actualización (tanto para lectura como para escritura).\n",
    "\n",
    "Python permite abrir archivo en modo binario (devolviendo los contenidos como bytes, sin descodificarlo) o bien en modo texto (devolviendo los contenidos como cadenas de texto, obtenidas de descodificar los bytes en función de la plataforma donde se ejecute el código o bien de la codificación especificada). Por defecto (es decir, si no se especifica el modo), los archivos se abren en modo texto, de modo que, por ejemplo, `r` y `rt` son equivalentes.\n",
    "\n",
    "Tanto el modo `w` como el modo `a` permiten escribir en un archivo. La diferencia entre estos modos radica en el tratamiento del contenido existente en el archivo: `w` sobrescribe el contenido del archivo, eliminando el contenido ya existente e incorporando el nuevo; en cambio, `a` escribe a continuación del contenido ya existente en el archivo, añadiendo el nuevo contenido después del contenido ya existente.\n",
    "\n",
    "El modo de actualización, `+`, permite abrir un archivo para escribir y leer. Así, tanto `w+` como `r+`, permitirán leer y escribir un archivo. La diferencia entre ambos modos recae en el comportamiento respecto al contenido existente en el archivo y a la existencia del propio archivo. Si especificamos `w+`, sobrescribiremos el contenido del archivo y crearemos el archivo si éste no existe; en cambio, si especificamos `r+`, mantendremos el contenido del archivo y se generará un error si el archivo no existe.\n",
    "\n",
    "A continuación se presentan algunos ejemplos del funcionamiento de los modos de apertura de archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentamos abrir para lectura un archivo inexistente, lo\n",
    "# que generará una excepción\n",
    "p = 'files_folder/a_new_file.txt'\n",
    "try:\n",
    "    with open(p, 'r') as inp:\n",
    "        pass\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentamos abrir el mismo archivo para escritura (creando por tanto\n",
    "# el archivo) y escribimos dos líneas\n",
    "with open(p, 'w') as out:\n",
    "    out.write(\"The file did not exist\\n\")\n",
    "    out.write(\"It now contains two sentences.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a leer ahora el fichero (ahora se leerá correctamente, ya que\n",
    "# ha sido creado en la celda anterior)\n",
    "try:\n",
    "    with open(p, 'r') as inp:\n",
    "        content = inp.read()\n",
    "        # Mostramos el contenido del fichero\n",
    "        print(content)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a escribir en el mismo archivo con el modo 'w', por lo\n",
    "# que se sobrescribirá el contenido anterior\n",
    "with open(p, 'w') as out:\n",
    "    out.write(\"What happens if we write again?\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrid ahora el archivo `a_new_file.txt` de la carpeta `files_folder` y comprobad como solo contiene la frase `What happens if we write again?`, ya que el contenido anterior (`The file did not exist...`) se ha sobrescrito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a escribir ahora en el mismo fichero, pero utilizando el modo\n",
    "# 'a', por lo que escribiremos a continuación del contenido ya existente.\n",
    "with open(p, 'a') as out:\n",
    "    out.write(\"And now, what happens if we write again?\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import UnsupportedOperation\n",
    "# Ahora intentaremos añadir otra frase en el archivo, y luego leer\n",
    "# en el mismo archivo (lo que generará un error)\n",
    "try:\n",
    "    with open(p, 'a') as out:\n",
    "        out.write(\"...and again?\\n\")\n",
    "        content = out.read()\n",
    "except UnsupportedOperation as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si abrís ahora el archivo, veréis que contiene el texto siguiente, resultado de las ejecuciones de las celdas anteriores:\n",
    "\n",
    "```\n",
    "What happens if we write again?\n",
    "And now, what happens if we write again?\n",
    "... and again?\n",
    "```\n",
    "\n",
    "Probemos ahora el comportamiento del modo de lectura con actualización:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo en modo de lectura con actualización, escribimos una\n",
    "# frase y leemos el contenido a partir del final de la escritura\n",
    "with open(p, 'r+') as out:\n",
    "    out.write(\"Trying the r+ mode!\")\n",
    "    content = out.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este último ejemplo, el archivo se ha abierto para lectura con actualización. Al escribir, escribimos por tanto al inicio del archivo (y sobrescribimos el contenido anterior conforme vamos escribiendo). Luego, al leer, leemos a partir de donde hemos terminado de escribir, por lo que solo se lee el contenido ya existente (que no hemos sobrescrito). El contenido del archivo es ahora por lo tanto:\n",
    "\n",
    "```\n",
    "Trying the r+ mode!write again?\n",
    "And now, what happens if we write again?\n",
    "...and again?\n",
    "```\n",
    "\n",
    "Fíjaos como la primera línea contiene la frase que hemos escrito en la celda anterior, seguida de los caracteres que quedaban de la frase original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3.- Otros detalles en la apertura de ficheros\n",
    "\n",
    "Además del *path* y el modo, la función [`open`](https://docs.python.org/3/library/functions.html#open) acepta otros argumentos opcionales, que gestionan el *buffering* de datos, la codificación, la gestión de los errores, la gestión del salto de línea, etc. El lector interesado puede consultar la [documentación oficial de la función `open`](https://docs.python.org/3/library/functions.html#open) (lectura opcional) para descubrir cómo funcionan estos argumentos y qué opciones se encuentran disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4.- Lectura de ficheros grandes\n",
    "\n",
    "Como hemos visto, el método [`read`](https://docs.python.org/3/library/os.html#os.read) lee todo el contenido del archivo. Es evidente, pues, que utilizar este método puede conllevar problemas de memoria y de eficiencia en nuestro código, sobre todo cuando el fichero a leer sea grande.\n",
    "\n",
    "Una alternativa para la lectura de archivos es hacerla línea a línea, de modo que sólo una línea del archivo se carga en memoria cada vez:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "p_big = 'files_folder/somehow_big_file.txt'\n",
    "\n",
    "# Cargamos el archivo somehow_big_file.txt completo y mostramos\n",
    "# el tamaño de la variable content en memoria\n",
    "with open(p_big, 'r') as f:\n",
    "    content = f.read()\n",
    "    size_in_bytes = getsizeof(content)\n",
    "    print(\"The size of the variable is: {} KB\\n\\n\".format(\n",
    "        size_in_bytes / 1024))\n",
    "\n",
    "# Leemos el fichero línea a línea (y únicamente las 5 primeras líneas),\n",
    "# mostrando el tamaño de la variable line\n",
    "with open(p_big, 'r') as f:\n",
    "    counter = 0\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        size_in_bytes = getsizeof(line)\n",
    "        print(\"The size of the variable is: {} KB\\n\\n\".format(\n",
    "            size_in_bytes / 1024))\n",
    "        counter += 1\n",
    "        if counter == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.- Creación de carpetas\n",
    "\n",
    "Hemos visto cómo podemos crear archivos abriéndolos en modo 'w' o 'a'. Para crear una carpeta o directorio, podemos utilizar los métodos [`mkdir`](https://docs.python.org/3.8/library/os.html#os.mkdir) o [`makedirs`](https://docs.python.org/3.8/library/os.html#os.makedirs):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la carpeta a_new_folder dentro de la carpeta\n",
    "# existente files_folder\n",
    "new_folder = 'files_folder/a_new_folder'\n",
    "os.mkdir(new_folder)\n",
    "\n",
    "# Creamos la carpeta an_empty_folder dentro de la carpeta\n",
    "# existente files_folder\n",
    "new_folder = 'files_folder/an_empty_folder'\n",
    "os.mkdir(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentamos crear la carpeta 2 dentro de la carpeta 1 dentro de la carpeta\n",
    "# a_new_folder que hemos creado en la celda anterior\n",
    "try:\n",
    "    new_folder = 'files_folder/a_new_folder/1/2'\n",
    "    os.mkdir(new_folder)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celda anterior genera una excepción, ya que la carpeta 'files_folder/a_new_folder/1' dentro de la cual queremos crear la carpeta '2' no existe. Si lo que queremos es crear tanto la carpeta '1' como la carpeta '2' dentro de la carpeta '1', podemos utilizar [`makedirs`](https://docs.python.org/3.8/library/os.html#os.makedirs):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos todas las carpetas que haya de la siguiente estructura de\n",
    "# carpetas\n",
    "new_folder = 'files_folder/a_new_folder/1/2/3'\n",
    "os.makedirs(new_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.- Borrar y renombrar\n",
    "\n",
    "La librería [`os`](https://docs.python.org/3.8/library/os.html) también provee de funciones para borrar archivos o directorios vacíos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos el archivo a_new_file.txt\n",
    "os.remove(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos la carpeta vacía an_empty_folder\n",
    "empty_fold = 'files_folder/an_empty_folder'\n",
    "os.rmdir(empty_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentamos borrar la carpeta files_folder, lo que generará\n",
    "# un error ya que esta contiene archivos\n",
    "try:\n",
    "    non_empty_fold = 'files_folder'\n",
    "    os.rmdir(non_empty_fold)\n",
    "except OSError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera análoga a la ejecución de un [`rmdir`](https://docs.python.org/3.8/library/os.html#os.rmdir) en una consola Linux, no podemos borrar una carpeta si esta contiene archivos. Si necesitamos borrar una carpeta y todos los archivos que esta contiene en Python, podemos hacerlo a mano (borrando primero los archivos dentro de la carpeta y luego la propia carpeta), o bien utilizando alguna función que ya incorpore este comportamiento, como [`rmtree`](https://docs.python.org/3.8/library/shutil.html#shutil.rmtree) del módulo [`shutil`](https://docs.python.org/3.8/library/shutil.html).\n",
    "\n",
    "La librería [`os`](https://docs.python.org/3.8/library/os.html#os.rmdir) también permite renombrar archivos y directorios a través de la función [`rename`](https://docs.python.org/3.8/library/os.html#os.rename):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos el archivo original_file.txt a dest_file.txt\n",
    "os.rename('files_folder/original_file.txt',\n",
    "          'files_folder/dest_file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4.- Funciones auxiliares de *paths*\n",
    "\n",
    "Más allá de la propia lectura, escritura, borrado y renombrado de ficheros, trabajar con archivos suele requerir otras funciones, a menudo auxiliares, que permiten construir lógicas complejas de gestión de archivos.\n",
    "\n",
    "Así, por ejemplo, es habitual tener que construir una ruta (un *path*), que indique dónde se encuentra un archivo en el sistema de ficheros a partir de fragmentos de esta ruta (por ejemplo, el nombre de la carpeta o ruta de carpetas, el nombre del archivo, etc.).\n",
    "\n",
    "El submódulo [`path`](https://docs.python.org/3.8/library/os.path.html) (del módulo [`os`](https://docs.python.org/3.8/library/os.html#os.makedirs)) implementa la función [`join`](https://docs.python.org/3.8/library/os.path.html#os.path.join) que une diferentes partes de la ruta de un archivo de manera *inteligente*, considerando el separador de directorios del sistema en que se ejecuta el código. Es una buena práctica utilizar esta función a la hora de especificar donde se encuentra un archivo en vez de concatenar manualmente las diferentes partes de la ruta, ya que esto mejora la compatibilidad del código en diferentes sistemas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos diferentes partes de un path con join\n",
    "path = \"/home\"\n",
    "full_path = os.path.join(path, \"User/Desktop\", \"filename.txt\")\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_full_path = os.path.join(path, \"User/Public/\", \"Documents\", \"\")\n",
    "print(another_full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer caso, el *path* generado ( `full_path`) correspondía a un fichero, mientras que en el segundo caso el *path* obtenido (` another_full_path`) era el de una carpeta o directorio (algo que podemos deducir por la `/` final). Tened en cuenta que, para indicar que el *path* que queremos obtener es el de una carpeta, hemos indicado como último elemento de la llamada a [`join`](https://docs.python.org/3/library/os.path.html#os.path.join) una cadena vacía (`\"\"`).\n",
    "\n",
    "Por otra parte, a partir de un *path* podemos obtener el nombre de la carpeta, el nombre del archivo, o la extensión del fichero con las funciones [`dirname`](https://docs.python.org/3/library/os.path.html#os.path.dirname), [`basename`](https://docs.python.org/3/library/os.path.html#os.path.basename) y [`splitext`](https://docs.python.org/3/library/os.path.html#os.path.splitext), respectivamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el nombre del directorio\n",
    "os.path.dirname(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el nombre del archivo\n",
    "os.path.basename(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la extensión del path\n",
    "os.path.splitext(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra funcionalidad a menudo necesaria en el tratamiento de ficheros es la de poder comprobar si un *path* existe, o si éste corresponde a un archivo normal, o bien a una carpeta. Estas tres comprobaciones las podemos hacer con las funciones [`exists`](https://docs.python.org/3.8/library/os.path.html#os.path.exists), [`isfile`](https://docs.python.org/3.8/library/os.path.html#os.path.isfile) y [`isdir`](https://docs.python.org/3.8/library/os.path.html#os.path.isdir), respectivamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = os.path.exists(full_path)\n",
    "print(\"Path {} exists?\\t\\t\\t{}\".format(full_path, e))\n",
    "\n",
    "path_1 = \"./\"\n",
    "e = os.path.exists(path_1)\n",
    "print(\"Path {} exists?\\t\\t\\t\\t\\t\\t\\t{}\".format(path_1, e))\n",
    "\n",
    "path_2 = \"3-ES-Ficheros_e_interacción_con_el_sistema.ipynb\"\n",
    "e = os.path.exists(path_2)\n",
    "print(\"Path {} exists?\\t{}\".format(path_2, e))\n",
    "\n",
    "path_3 = \"/home\"\n",
    "e = os.path.exists(path_3)\n",
    "print(\"Path {} exists?\\t\\t\\t\\t\\t\\t{}\".format(path_3, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer *path* no corresponde a ningún path existente, por lo que [`exists`](https://docs.python.org/3.8/library/os.path.html#os.path.exists) devuelve `False`. En cambio, tanto los *paths* relativos `./` y `3-ES-Ficheros_e_interacción_con_el_sistema.ipynb` como el *path* absoluto` /home` existen en el sistema, de modo que [`exists`](https://docs.python.org/3.8/library/os.path.html#os.path.exists) devuelve `True`. Es importante notar que [`exists`](https://docs.python.org/3.8/library/os.path.html#os.path.exists) reconoce tanto archivos normales como carpetas o directorios. En cambio, la función [`isfile`](https://docs.python.org/3.8/library/os.path.html#os.path.isfile) devolverá `True` únicamente si el *path* existe y este es un archivo normal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_f = os.path.isfile(full_path)\n",
    "print(\"Path {} is file?\\t\\t\\t{}\".format(full_path, is_f))\n",
    "\n",
    "is_f = os.path.isfile(path_1)\n",
    "print(\"Path {} is file?\\t\\t\\t\\t\\t\\t{}\".format(path_1, is_f))\n",
    "\n",
    "is_f = os.path.isfile(path_2)\n",
    "print(\"Path {} is file?\\t{}\".format(path_2, is_f))\n",
    "\n",
    "is_f = os.path.isfile(path_3)\n",
    "print(\"Path {} is file?\\t\\t\\t\\t\\t\\t{}\".format(path_3, is_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, [`isfile`](https://docs.python.org/3.8/library/os.path.html#os.path.isfile) reconoce únicamente el tercer *path* como archivo, ya que el primero no existe y los otros dos corresponden a carpetas.\n",
    "\n",
    "Vemos ahora el resultado de llamar [`isdir`](https://docs.python.org/3.8/library/os.path.html#os.path.isdir) con los mismos *paths*:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_d = os.path.isdir(full_path)\n",
    "print(\"Path {} is directory?\\t\\t{}\".format(full_path, is_d))\n",
    "\n",
    "is_d = os.path.isdir(path_1)\n",
    "print(\"Path {} is directory?\\t\\t\\t\\t\\t\\t{}\".format(path_1, is_d))\n",
    "\n",
    "is_d = os.path.isdir(path_2)\n",
    "print(\"Path {} is directory?\\t{}\".format(path_2, is_d))\n",
    "\n",
    "is_d = os.path.isdir(path_3)\n",
    "print(\"Path {} is directory?\\t\\t\\t\\t\\t{}\".format(path_3, is_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, de nuevo, obtenemos `False` para el primer *path*, ya que éste no existe, y obtenemos` True` para los dos *paths* que representan directorios, `./` y `/home`.\n",
    "\n",
    "## 1.5.- Listado de directorios\n",
    "\n",
    "Para obtener todos los contenidos que hay en un directorio podemos utilizar la función [`scandir`](https://docs.python.org/3/library/os.html#os.scandir):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos todas las entradas de la carpeta files_folder\n",
    "folder_name = 'files_folder/'\n",
    "with os.scandir(folder_name) as dir_list:\n",
    "    for entry in dir_list:\n",
    "        print(entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos obtener una lista de los archivos de una carpeta, podemos combinar [`scandir`](https://docs.python.org/3/library/os.html#os.scandir) con la función [`isfile`](https://docs.python.org/3.8/library/os.path.html#os.path.isfile) que hemos visto en una sección anterior:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos todos los archivos de la carpeta files_folder\n",
    "with os.scandir(folder_name) as dir_list:\n",
    "    for entry in dir_list:\n",
    "        if os.path.isfile(entry.path):\n",
    "            print(entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, podemos utilizamos el método [`is_file`](https://docs.python.org/3.8/library/os.path.html#os.path.isfile) de las propias entradas, ya que [`scandir`](https://docs.python.org/3/library/os.html#os.scandir) devuelve un iterador que recorre objetos de tipo [`DirEntry`](https://docs.python.org/3/library/os.html#os.DirEntry), que implementan este método:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos todos los archivos de la carpeta files_folder\n",
    "with os.scandir(folder_name) as dir_list:\n",
    "    for entry in dir_list:\n",
    "        if entry.is_file():\n",
    "            print(type(entry), entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6.- Patrones de Unix *shell*\n",
    "\n",
    "Combinando la posibilidad de listar el contenido de directorios con las expresiones regulares que vimos en la unidad de estructuras de datos avanzadas (o, incluso, tal vez solo con otras funciones básicas de cadenas, como [`startswith`](https://docs.python.org/3/library/stdtypes.html#str.startswith)), podemos seleccionar un subconjunto de archivos que cumplan alguna característica concreta. Así, por ejemplo, podríamos procesar solo los ficheros con extensión .txt de la misma carpeta que en el ejemplo anterior, haciendo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos todos los archivos de la carpeta files_folder\n",
    "with os.scandir(folder_name) as dir_list:\n",
    "    for entry in dir_list:\n",
    "        if entry.is_file() and entry.name.endswith(\".txt\"):\n",
    "            print(entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una alternativa para hacer este tipo de operaciones es utilizar el módulo [`glob`](https://docs.python.org/3.8/library/glob.html), que permite obtener los paths que siguen un determinado patrón especificado utilizando la sintaxis de una *shell* de Unix (es decir, la misma sintaxis que utilizaríamos si estuviéramos navegando por el sistema de ficheros desde una *shell*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Obtenemos una lista con los nombres de los ficheros de notebook de Python\n",
    "glob.glob('*.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listamos el contenido de la carpeta files_folder\n",
    "glob.glob('./files_folder/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listamos los archivos .txt que hay dentro de la carpeta files_folder\n",
    "glob.glob('./files_folder/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listamos todos los archivos que hay en el path actual, buscando\n",
    "# recursivamente dentro de las carpetas\n",
    "glob.glob('*', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7.- Obtención de metadatos de los ficheros\n",
    "\n",
    "El submódulo [`path`](https://docs.python.org/3.8/library/os.path.html) también contiene funciones para obtener metadatos de los archivos, por ejemplo su tamaño ([`getsize`](https://docs.python.org/3/library/os.path.html#os.path.getsize)), o el instante de la última modificación ([`getmtime`](https://docs.python.org/3/library/os.path.html#os.path.getmtime)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el tamaño del archivo p_big\n",
    "p_big_size = os.path.getsize(p_big)\n",
    "print(\"The file {} is {} KB\".format(p_big, p_big_size / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Obtenemos la fecha de última modificación\n",
    "unx_ts_mtime = os.path.getmtime(p_big)\n",
    "print(\"The last modification time is: {} (unix ts)\".format(unx_ts_mtime))\n",
    "\n",
    "print(\"which is: {}\".format(\n",
    "    datetime.utcfromtimestamp(unx_ts_mtime).strftime('%Y-%m-%d %H:%M:%S')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos obtener otros metadatos, como las que obtendríamos haciendo un [`stat`](http://man7.org/linux/man-pages/man2/stat.2.html) de Linux sobre el archivo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stat\n",
    "\n",
    "# Mostramos los bits de protección del archivo\n",
    "print(oct(stat.S_IMODE(os.stat(p_big).st_mode)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenéis curiosidad por saber cómo funcionan los bits de permiso de los ficheros en unix, os recomendamos leer las tres partes de la serie de artículos sobre los permisos ([1](http://www.filepermissions.com/articles/what-are-file-permissions-in-linux-and-mac), [2](http://www.filepermissions.com/articles/understanding-octal-file-permissions), y [3](http://www.filepermissions.com/artículos/sticky-bit-suid-and-sgid)), todas ellas lecturas opcionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2.- Trabajo con ficheros comprimidos\n",
    "\n",
    "Un archivo comprimido es un archivo que contiene uno o varios archivos y/o carpetas, codificados de tal manera que ocupan menos espacio en disco que los archivos originales. Se utilizan ficheros comprimidos, por ejemplo, para transferir más rápidamente contenido a través de una red, o para aprovechar mejor el espacio de disco.\n",
    "\n",
    "Distinguimos entre compresión **sin pérdida** y compresión **con pérdida**. La compresión sin pérdida se caracteriza por permitir recuperar la totalidad de los datos de los archivos originales a partir de los ficheros comprimidos. En cambio, en la compresión con pérdida, se pueden perder algunos bits de información. Se utiliza compresión con pérdida principalmente en imágenes y vídeo, donde a menudo las personas que visualizan este contenido no llegan a notar la pérdida. En cambio, en ficheros de texto se suele utilizar compresión sin pérdida.\n",
    "\n",
    "En este notebook, se explicará cómo trabajar con archivos comprimidos zip, uno de los formatos más populares de compresión sin pérdida, utilizando el módulo [`zipfile`](https://docs.python.org/3.8/library/zipfile.html). La otra alternativa muy popular para comprimir sin pérdida es usar gzip. El notebook no incluye explicaciones sobre cómo trabajar con archivos gzip, ya que el funcionamiento es muy similar al que se describe para zip. El lector interesado puede leer la documentación del módulo [`gzip`](https://docs.python.org/3.8/library/gzip.html) para conocer las funciones que permiten trabajar con archivos gzip desde Python (lectura opcional) .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.- Lectura y escritura de ficheros comprimidos\n",
    "\n",
    "De manera similar a los archivos genéricos, lo primero que hay que hacer para leer o crear un archivo comprimido zip es abrirlo, especificando su *path* y el modo de apertura. Cuando hayamos finalizado la operación, también habrá que cerrarlo. Podemos utilizar la misma sintaxis que hemos visto en el apartado anterior para gestionar la apertura y cierre de los archivos comprimidos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "\n",
    "zip_file = 'files_folder/compressed_file.zip'\n",
    "# Creamos el fichero zip_file especificando el modo de compresión ZIP_DEFLATED\n",
    "with zf.ZipFile(zip_file, 'w', compression=zf.ZIP_DEFLATED) as zip_f:\n",
    "    # Añadimos el fichero p_big al zip\n",
    "    zip_f.write(p_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior, hemos abierto un archivo zip en modo de escritura (especificado por 'w'), de manera que el archivo se creará si no existe, o se sobrescribirá si ya existía; y hemos especificado el método de compresión [`ZIP_DEFLATED`](https://docs.python.org/3.8/library/zipfile.html#zipfile.ZIP_DEFLATED). Con el archivo abierto, le hemos añadido el archivo ya existente `p_big`. Comprobamos el resultado de la compresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el tamaño del archivo original p_big\n",
    "p_big_size = os.path.getsize(p_big)\n",
    "print(\"The file {} is {} KB\".format(p_big, p_big_size / 1024))\n",
    "\n",
    "# Obtenemos el tamaño del archivo zip_file (que contiene el archivo\n",
    "# p_big comprimido)\n",
    "zip_file_size = os.path.getsize(zip_file)\n",
    "print(\"The file {} is {} KB\".format(zip_file, zip_file_size / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así pues, el archivo original de 249KB ha pasado a ocupar sólo 1.3KB al ser comprimido.\n",
    "\n",
    "Comprobamos ahora que podemos recuperar el archivo original a partir del archivo comprimido. En primer lugar, vamos a calcular un [hash](https://en.wikipedia.org/wiki/Hash_function) del contenido del archivo, para poder asegurar que el archivo que recuperaremos es exactamente el mismo que el archivo original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def sha256_file_content(p):\n",
    "    \"\"\"\n",
    "    Returns the sha256 hash of the content of the file p.\n",
    "    \"\"\"\n",
    "    with open(p, 'rb') as f:\n",
    "        content = f.read()\n",
    "        h = hashlib.sha256(content).hexdigest()\n",
    "    return h\n",
    "\n",
    "\n",
    "# Obtenemos el hash del contenido del archivo p_big\n",
    "orig_hash = sha256_file_content(p_big)\n",
    "print(\"sha256: {}\".format(orig_hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos el archivo p_big\n",
    "os.remove(p_big)\n",
    "\n",
    "# Comprobamos que se ha borrado\n",
    "is_f = os.path.isfile(p_big)\n",
    "print(\"Path {} is file? {}\".format(p_big, is_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo zip en modo de lectura\n",
    "with zf.ZipFile(zip_file, 'r') as zip_f:\n",
    "    # Mostramos el contenido del zip\n",
    "    print(zip_f.printdir())\n",
    "    # Descomprimimos todo el contenido del zip\n",
    "    zip_f.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que el archivo se ha descomprimido\n",
    "is_f = os.path.isfile(p_big)\n",
    "print(\"Path {} is file? {}\".format(p_big, is_f))\n",
    "\n",
    "# Comprobamos que el contenido del fichero es exactamente el mismo\n",
    "uncomp_hash = sha256_file_content(p_big)\n",
    "print(\"sha256: {}\".format(uncomp_hash))\n",
    "print(\"Hash are equal?: {}\".format(uncomp_hash == orig_hash))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1.- El path y el modo\n",
    "\n",
    "En cuanto al *path* de los ficheros comprimidos, las mismas consideraciones que se han hecho sobre ficheros son aplicables en el caso de los archivos comprimidos.\n",
    "\n",
    "Ya hemos visto como los modos de lectura 'r' y escritura 'w' de archivos zip funcionan de manera similar a los del módulo [`os`](https://docs.python.org/3/library/os.html) . Así, también disponemos de un modo de concatenación, 'a' (del inglés, *append*), que permite añadir contenido a un zip sin sobrescribir el contenido existente; y del modo de creación y escritura e**x**clusiva, 'x', que a diferencia del modo de escritura, generará una excepción si el archivo que se intenta crear ya existe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2.- Otros detalles en la apertura de ficheros\n",
    "\n",
    "Además del *path* y el modo, [`ZipFile`](https://docs.python.org/3.8/library/zipfile.html) acepta otros argumentos opcionales, que gestionan el formato de compresión, la extensión para permitir archivos mayores de 4GB, y la comprobación de *timestamps*. El lector interesado puede consultar la [documentación oficial de la clase `ZipFile`](https://docs.python.org/3.8/library/zipfile.html) (lectura opcional) para descubrir cómo funcionan estos argumentos y qué opciones se encuentran disponibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3.- Lectura de archivos grandes\n",
    "\n",
    "Hemos visto que podemos utilizar el método [`extractall`](https://docs.python.org/3/library/zipfile.html#zipfile.ZipFile.extractall) para extraer todo el contenido de un zip. Ahora bien, si el archivo zip es muy grande, contiene varios archivos, y sólo necesitamos un subconjunto de estos, será más eficiente descomprimir únicamente los archivos que necesitemos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo zip en modo de lectura\n",
    "zip_with_multiple_files = \"files_folder/zip_with_multiple_files.zip\"\n",
    "with zf.ZipFile(zip_with_multiple_files, 'r') as zip_f:\n",
    "    # Descomprimimos únicamente el archivo file_2.txt\n",
    "    zip_f.extract(\"file_2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijaos como, para extraer un único archivo, tendremos que saber cómo se llama este archivo, información que podemos saber ya, o bien que podemos obtener, como hemos visto, con [`printdir`](https://docs.python.org/3.8/library/zipfile.html#zipfile.ZipFile.printdir). Más adelante, veremos también otra alternativa para obtener esta información.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.- Borrar, renombrar y crear carpetas\n",
    "\n",
    "El módulo [`zipfile`](https://docs.python.org/3.8/library/zipfile.html) no permite, de manera nativa, borrar o renombrar ficheros que se encuentran dentro de un zip. Por tanto, lo que habrá que hacer si necesitamos realizar estas acciones será implementar manualmente a partir de los modos de lectura y escritura que hemos visto en el apartado anterior. Así, por ejemplo, si queremos borrar un cierto archivo de un zip, habrá descomprimir el zip, y volver a crear un nuevo zip con el mismo contenido que el archivo original, pero sin incluir el fichero que queremos borrar.\n",
    "\n",
    "Para crear una carpeta dentro de un archivo zip, procederemos a crear la carpeta fuera de este, y lo añadiremos después como si fuera un archivo ordinario, por ejemplo, con la función `write`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.- Funciones auxiliares de paths, listados y metadatos\n",
    "\n",
    "De manera análoga a las funciones que permitían comprobar si un archivo era un directorio o un archivo normal, el módulo [`zipfile`](https://docs.python.org/3.8/library/zipfile.html) dispone del método [`is_zipfile`](https://docs.python.org/3.8/library/zipfile.html#zipfile.is_zipfile) que permite comprobar si un archivo es un archivo zip válido:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izf = zf.is_zipfile(zip_file)\n",
    "print(\"The file {} is a zip file?: {}\".format(zip_file, izf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, ya hemos visto como el método [`printdir`](https://docs.python.org/3.8/library/zipfile.html#zipfile.ZipFile.printdir) nos permite obtener un listado de los contenidos de un archivo zip:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo zip en modo de lectura\n",
    "zip_with_mult_files = \"files_folder/zip_with_multiple_files.zip\"\n",
    "with zf.ZipFile(zip_with_mult_files, 'r') as zip_f:\n",
    "    # Mostramos el contenido del zip\n",
    "    print(zip_f.printdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra alternativa para obtener información sobre los contenidos de un zip es utilizar la clase [`ZipInfo`](https://docs.python.org/3.8/library/zipfile.html#zipfile.ZipInfo), que nos devuelve precisamente este tipo de información:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zf.ZipFile(zip_with_mult_files, 'r') as zip_f:\n",
    "    # Obtenemos un objeto ZipInfo del archivo zip_with_mult_files\n",
    "    info_list = zip_f.infolist()\n",
    "\n",
    "    # Para cada archivo dentro del zip, mostramos la\n",
    "    # información del fichero\n",
    "    for info in info_list:\n",
    "        print(\"Filename: {}\".format(info.filename))\n",
    "        print(\"\\tFile size: {} bytes\".format(info.file_size))\n",
    "        print(\"\\tIs dir?: {}\".format(info.is_dir()))\n",
    "        print(\"\\tDate and time: {}\".format(info.date_time))\n",
    "        print(\"\\tCompression type: {}\".format(info.compress_type))\n",
    "        print(\"\\tCRC: {}\\n\".format(info.CRC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que remarcar que un archivo zip es un archivo en toda regla. Por lo tanto, podemos obtener metadatos del propio archivo zip con las funciones que hemos visto anteriormente del módulo [`os`](https://docs.python.org/3.8/library/os.html). Por ejemplo, podríamos obtener el tamaño del zip utilizando [`getsize`](https://docs.python.org/3.8/library/os.path.html#os.path.getsize):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el tamaño del archivo zip_with_mult_files\n",
    "s_zip_with_mult_files = os.path.getsize(zip_with_mult_files)\n",
    "print(\"The file {} is {} KB\".format(zip_with_mult_files,\n",
    "                                    s_zip_with_mult_files / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3.- Lectura y escritura de ficheros con pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas situaciones, podremos utilizar librerías de más alto nivel para leer y/o escribir archivos. Así, por ejemplo, la librería pandas, permite cargar datos de un archivo CSV a un _dataframe_ a través de la función [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
    "\n",
    "Ahora cargaremos los datos del fichero `marvel-wikia-data.csv`, que contiene datos sobre personajes de cómic de Marvel. El conjunto de datos original en el que se basa el que utilizaremos fue creado por la web [FiveThirtyEight](https://fivethirtyeight.com/), que escribe artículos basados en datos sobre deportes y noticias, y que pone a disposición pública los [conjuntos de datos](https://github.com/fivethirtyeight/data) que recoge para sus artículos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos los datos del fichero \"marvel-wikia-data.csv\" en un 'dataframe'\n",
    "data = pd.read_csv(\"data/marvel-wikia-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) acepta un gran abanico de parámetros opcionales que permiten configurar con detalle cómo se tiene que realizar la importación del archivo csv. A continuación, veremos algunos de ellos, ajustando la importación de los datos de Marvel.\n",
    "\n",
    "Fijémonos, en primer lugar, en la importación de las columnas numéricas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, ha habido un problema en la importación de los años en los que los personajes aparecen por primera vez en los cómics, ya que la media es 1.88 y, en cambio, los cómics aparecieron en el siglo XX. Observando el contenido del archivo csv:\n",
    "\n",
    "```\n",
    "page_id, name, urlslug, ID, ALIGN, EYE, HAIR, SEX, GSM, ALIVE, Appearances, FIRST Appearance, Year\n",
    "1678, Spider-Man (Peter Parker), \\ / Spider-Man_ (Peter_Parker), Secreto Identity, Good Characters, Hazel Eyes, Brown Hair, Male Characters, dontknow, Living Characters, 4043, Aug-62,1.962\n",
    "7139, Captain America (Steven Rogers), \\ / Captain_America_ (Steven_Rogers), Public Identity, Good Characters, Blue Eyes, White Hair, Male Characters ,, Living Characters, 3360, Mar-41,1.941\n",
    "...\n",
    "```\n",
    "\n",
    "podemos ver como los años se expresan usando un punto como separador de millares, que pandas está interpretando como separador decimal. Por lo tanto, para asegurar que los años se importan correctamente, podemos indicar que el separador de decimales sea la coma (`,`) con el parámetro `decimal`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/marvel-wikia-data.csv\", decimal=\",\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, parece que los años se han importado correctamente, aunque la media sigue siendo más baja del valor que esperaríamos. Observando los datos para el campo año, podemos comprobar como la última fila contiene un 0, valor que hace bajar la media:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Year\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos indicar que queremos omitir esta fila en la carga de datos con el parámetro `skiprows`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/marvel-wikia-data.csv\", decimal=\",\", skiprows=[31])\n",
    "data[[\"Year\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, esto hace que la media suba de $1677.46$ a $1735.31$, y el mínimo pase de ser $0$ (el valor de la fila que hemos omitido) a $1047$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si seguimos observando los datos que se han cargado, podemos observar también cómo aparecen varias inversa (`\\`), por ejemplo, antes de comillas dobles (`\"`) o de las barras (`/`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas barras invertidas se están usando para escapar caracteres especiales, lo que también podemos indicar a la función de carga del csv, con el parámetro `escapechar`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/marvel-wikia-data.csv\", decimal=\",\", skiprows=[31],\n",
    "                   escapechar=\"\\\\\")\n",
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro detalle a considerar es que se utiliza tanto el valor `NaN` como la cadena de caracteres `'dontknow'` para indicar valores desconocidos o perdidos. Podemos indicar que hay que interpretar esta cadena como valor perdido con el método `na_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/marvel-wikia-data.csv\", decimal=\",\", skiprows=[31],\n",
    "                   escapechar=\"\\\\\", na_values=[\"dontknow\"])\n",
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, otra de las funcionalidades bastante potentes de la función `read_csv` es la de aplicar alguna función a los elementos de cada columna antes de incoporarlo al dataframe. Así, por ejemplo, la columna `FIRST APPEARANCE` contiene el mes (abreviado), un guión, y el año en formato de dos dígitos. Si quisiéramos que esta columna contuviera únicamente al año y en formato de 4 dígitos, podríamos crear una función anónima que hiciera la conversión, y pasar esta función a `read_csv` con el parámetro` converters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/marvel-wikia-data.csv\",\n",
    "    decimal=\",\", skiprows=[31], escapechar=\"\\\\\", na_values=[\"dontknow\"],\n",
    "    converters={\"FIRST APPEARANCE\": lambda x: int(x.split(\"-\")[1])+1900}\n",
    ")\n",
    "data[[\"FIRST APPEARANCE\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más allá de los ficheros csv, hay otros formatos que también se utilizan a menudo para intercambiar o guardar datos. Pandas dispone de varias funciones para cargar datos provenientes de los formatos de datos más populares, tales como, json ([`read_json`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html#pandas.read_json)) o excel ([`read_excel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html#pandas.read_excel)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Serialización de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **serialización** de datos es el proceso de convertir datos estructurados (por ejemplo, una lista o un diccionario) en algún formato que permita almacenarlos o transmitirlos, de manera que sea posible después, a partir de un proceso de deserialización, recuperar los datos con su estructura original.\n",
    "\n",
    "La serialización puede ser útil, por ejemplo, para transmitir un conjunto de datos a través de la red, para almacenar datos que serán tratados desde Python, o como método para crear *checkpoints* que permitan recuperar el estado de nuestros *scripts* en códigos que tardan mucho tiempo en finalizar.\n",
    "\n",
    "El método principal de serialización en Python se encuentra implementado por el módulo [`pickle`](https://docs.python.org/3.8/library/pickle.html) de la librería estándar.\n",
    "\n",
    "\n",
    "## 4.1- Serialización de datos con pickle\n",
    "\n",
    "Vamos a ver un ejemplo sencillo de serialización y deserialización de una estructura de datos simple, un diccionario:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Creamos un diccionario\n",
    "a_dict = {\"Spain\": 34, \"United Kingdom\": 44}\n",
    "\n",
    "# Serializamos el diccionario y mostramos el resultado de la serialización\n",
    "serialized_dict = pickle.dumps(a_dict)\n",
    "print(serialized_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserializamos el diccionario, creando un nuevo diccionario a partir del\n",
    "# contenido serializado\n",
    "des_dict = pickle.loads(serialized_dict)\n",
    "\n",
    "# Comprobamos si el contenido del diccionario original y del deserializado son\n",
    "# iguales\n",
    "des_dict == a_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de ver un ejemplo de serialización de un diccionario, veremos otro que se acerca más al uso real de [`pickle`](https://docs.python.org/3.8/library/pickle.html) en la minería de datos. Supongamos que hemos entrenado un modelo de aprendizaje automático a partir de unos datos, y que ahora lo queremos guardar para usarlo posteriormente para hacer predicciones. En este caso, puede ser útil almacenar el modelo aprendido utilizando [`pickle`](https://docs.python.org/3.8/library/pickle.html), y recuperarlo después cuando sea necesario hacer predicciones. Veamos un ejemplo con la creación de un árbol de decisión para el conjunto de datos de flores de Iris:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Cargamos los datos\n",
    "data = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Creamos los conjuntos de test y aprendizaje\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_df, y, test_size=0.1)\n",
    "\n",
    "# Entrenamos un árbol de decisión\n",
    "dec_tree = DecisionTreeClassifier(splitter=\"random\", criterion=\"entropy\")\n",
    "dec_tree.fit(x_train, y_train)\n",
    "\n",
    "# Probamos el clasificador con los datos de test\n",
    "y_test_predicted = dec_tree.predict(x_test)\n",
    "print(\"Predicted classes: \\t\" + str(y_test_predicted))\n",
    "print(\"Accuracy: \\t\\t\" + str(dec_tree.score(x_test, y_test)))\n",
    "\n",
    "# Guardamos el modelo aprendido serializado en un fichero\n",
    "p = \"files_folder/dec_tree_model.pickle\"\n",
    "with open(p, \"wb\") as f:\n",
    "    pickle.dump(dec_tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la variable dec_tree (para simular el hecho de terminar la\n",
    "# ejecución de nuestro script de entrenamiento o bien la transmisión del\n",
    "#  archivo a otra máquina)\n",
    "del dec_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo guardado\n",
    "with open(p, \"rb\") as f:\n",
    "    dec_tree_des = pickle.load(f)\n",
    "\n",
    "# Comprobamos que el modelo guardado se ha recuperado correctamente\n",
    "y_test_predicted_des = dec_tree_des.predict(x_test)\n",
    "print(\"Predicted classes: \\t\" + str(y_test_predicted_des))\n",
    "print(\"Accuracy: \\t\\t\" + str(dec_tree_des.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos detalles importantes a notar en el código anterior. Por un lado, tened en cuenta que para leer o escribir el resultado de una deserialización o serialización, utilizamos [`load`](https://docs.python.org/3/library/pickle.html#pickle.load) y [`dump`](https://docs.python.org/3/library/pickle.html#pickle.dump) (respectivamente) en vez de [`loads`](https://docs.python.org/3/library/pickle.html#pickle.loads) y [`dumps`](https://docs.python.org/3/library/pickle.html#pickle.dumps) (a diferencia del ejemplo del diccionario). Las funciones [`load`](https://docs.python.org/3/library/pickle.html#pickle.load) y [`dump`](https://docs.python.org/3/library/pickle.html#pickle.dump) permiten leer y escribir el resultado de una serialización o deserialización en un fichero, mientras que [`loads`](https://docs.python.org/3/library/pickle.html#pickle.loads) y [`dumps`](https://docs.python.org/3/library/pickle.html#pickle.dumps) devuelven una cadena de bytes. Por otra parte, notad como es necesario abrir los archivos en modo binario (`rb` para leer o `wb` para escribir)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2- Consideraciones sobre la serialización de datos\n",
    "\n",
    "\n",
    "**¡Es importante ser conscientes de las situaciones en las que es útil utilizar serialización con [`pickle`](https://docs.python.org/3.8/library/pickle.html)!** Hay que tener en cuenta que [`pickle`](https://docs.python.org/3.8/library/pickle.html) sólo sirve para transferir datos entre programas hechos con Python, que puede haber incompatibilidades entre versiones, y que no es un método seguro de transferencia de datos. En este sentido, tenemos que asegurar que sólo deserializamos datos de confianza, ya que la deserialización puede provocar ejecución de código indeseado.\n",
    "\n",
    "En cuanto a qué tipos de datos podemos serializar con Python, en general encontraremos que es inmediato serializar tipos básicos (enteros, flotantes, cadenas de caracteres, booleanos, etc.), tipos compuestos de tipo serializables (diccionarios, tuplas, listas, conjuntos, etc.) y clases y funciones definidas en el ámbito global.\n",
    "\n",
    "Teniendo en cuenta las características que hemos descrito, ¿cuando será pues una buena alternativa utilizar serialización con pickle en vez de utilizar un formato de datos estándar tales como JSON, XML, o CSV? La siguiente tabla recoge la alternativa a utilizar en función de las propiedades de la situación:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Propiedad | Pickle | JSON / XML / CSV / Otros |\n",
    "| ---- |: ----: |: ----: |\n",
    "| Intercambio de datos sin confianza entre las partes |. | x |\n",
    "| Compatibilidad con otros lenguajes de programación (diferentes de Python) u otros programas |. | x |\n",
    "| Almacenamiento a largo plazo (posibles cambios de versión) |. | x |\n",
    "| Ejecución en diferentes máquinas, que tienen diferentes versiones de las librerías que proporcionan los tipos de datos almacenados |. | x |\n",
    "| Necesidad de lectura por parte de humanos |. | x |\n",
    "| Necesidad de almacenar objetos de manera rápida (por el programador), sin tener que decidir cómo representar el objeto | x |. |\n",
    "| Almacenamiento temporal (por ejemplo, *checkpoints* en la ejecución de un *script*) | x |. |\n",
    "| Necesidad de guardar el estado de nuestro programa (en vez de conjuntos de datos con cierta homogeneidad) | x |. |\n",
    "| Necesidad de almacenar funciones | x |. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.- Interacción con bases de datos\n",
    "\n",
    "El [PEP249](https://www.python.org/dev/peps/pep-0249/) describe la especificación de la API para acceder a bases de datos desde Python. La mayoría de los sistemas gestores de bases de datos (SGBD) más populares siguen esta especificación, por lo que hay bastante similitud en cómo se accede a los diferentes motores de bases de datos desde Python.\n",
    "\n",
    "Así pues, el procedimiento general para interactuar con una base de datos desde Python consta de los siguientes pasos:\n",
    "1. Importar el módulo que provee de la interfaz con la base de datos (específico para cada SGBD).\n",
    "2. Crear una conexión con la base de datos, proveyendo datos sobre la localización de la base de datos y, en su caso, la autenticación.\n",
    "3. Obtener un cursor sobre la conexión creada en el paso anterior.\n",
    "4. Ejecutar las sentencias SQL deseadas.\n",
    "5. Si las sentencias eran de consulta, recuperar los datos devueltos por la base de datos.\n",
    "6. Cerrar la conexión.\n",
    "\n",
    "Para ejemplificar el proceso, vamos a crear una nueva base de datos SQLite, donde guardaremos los datos de los personajes de Marvel (que cargaremos previamente del csv como hemos hecho anteriormente) y haremos consultas sobre estos datos utilizando SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos del csv de Marvel en un dataframe de pandas\n",
    "data = pd.read_csv(\n",
    "    \"data/marvel-wikia-data.csv\", decimal=\",\", escapechar=\"\\\\\",\n",
    "    na_values=[\"dontknow\"],\n",
    "    converters={\"FIRST APPEARANCE\": lambda x: int(x.split(\"-\")[1])+1900},\n",
    "    skiprows=[31])\n",
    "\n",
    "# Obtenemos una cadena con la lista de columnas, que utilizaremos para crear\n",
    "# la tabla de la base de datos\n",
    "cols = \", \".join(data.columns)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos SQLite3\n",
    "import sqlite3\n",
    "\n",
    "# Creamos una conexión con la base de datos marvel.db\n",
    "conn = sqlite3.connect('files_folder/marvel.db')\n",
    "\n",
    "# Obtenemos un cursor sobre la conexión\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Creamos una tabla utilizando los nombres de las columnas del dataframe\n",
    "sql_create_stm = \"CREATE TABLE marvel_chars ({})\".format(cols)\n",
    "print(sql_create_stm)\n",
    "\n",
    "# Ejecutamos la sentencia SQL de creación de la tabla\n",
    "cur.execute(sql_create_stm)\n",
    "\n",
    "# Guardamos los cambios (hacemos un commit en la db)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear la tabla de la base de datos, hemos utilizado una sentencia SQL de creación de tablas (`CREATE TABLE`).\n",
    "\n",
    "Una vez hemos creado la tabla, podemos consultar su contenido ejecutando un `SELECT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos SELECT * sobre toda la tabla\n",
    "sql_sel_stm = \"SELECT * FROM marvel_chars\"\n",
    "cur.execute(sql_sel_stm)\n",
    "\n",
    "# Recuperamos los resultados\n",
    "results = cur.fetchall()\n",
    "\n",
    "# Mostramos los resultados: la tabla de la base de datos está vacía\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como acabamos de crear la tabla, esta está vacía, y el `SELECT` no devuelve ninguna fila. Ahora, insertaremos los datos del *dataframe* en la base de datos, iterando por cada fila del *dataframe* e insertando cada fila en la tabla con un `INSERT`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteramos por cada fila de la tabla\n",
    "for index, row in data.iterrows():\n",
    "    # Insertamos los datos en la tabla marvel_chars\n",
    "    cur.execute(\"INSERT INTO marvel_chars VALUES \"\n",
    "                \"(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", row)\n",
    "\n",
    "# Hacemos un commit de los cambios\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez insertadas los datos en la base de datos, podemos repetir el `SELECT *` que hemos realizado anteriormente, y recuperar así todos los datos que hemos insertado en la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos SELECT * sobre toda la tabla\n",
    "sql_sel_stm = \"SELECT * FROM marvel_chars\"\n",
    "cur.execute(sql_sel_stm)\n",
    "\n",
    "# Recuperamos los resultados\n",
    "results = cur.fetchall()\n",
    "\n",
    "# Mostramos los resultados: la tabla de la base de datos contiene los datos\n",
    "# de los personajes de Marvel\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ejecutar consultas SQL sobre la tabla que acabamos de crear. Así, por ejemplo, si queremos recuperar sólo el nombre de los personajes femeninos, podríamos hacer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos la consulta SQL\n",
    "sql_sel_stm = \"SELECT name FROM marvel_chars WHERE sex = 'Female Characters'\"\n",
    "cur.execute(sql_sel_stm)\n",
    "\n",
    "# Mostramos los resultados\n",
    "results = cur.fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos terminado de trabajar con la base de datos, es importante recordar cerrar el recurso:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerramos la conexión\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante notar que si hubiéramos querido hacer lo mismo con una base de datos MySQL en vez de SQLite, habría que cambiar la librería a usar (el `import` del inicio del código), pero luego el código sería en general el mismo, y funcionaría haciendo únicamente pequeñas adaptaciones (por ejemplo, en la creación de la conexión)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.- Interacción con el sistema operativo\n",
    "\n",
    "Hasta ahora hemos visto cómo interactuar con el sistema operativo a través de la lectura o escritura de archivos. En esta sección, veremos cómo podemos ejecutar programas externos o comandos en la consola del sistema desde nuestro código Python, utilizando el módulo [`subprocess`](https://docs.python.org/3.8/library/subprocess.html).\n",
    "\n",
    "El módulo [`subprocess`](https://docs.python.org/3.8/library/subprocess.html) permite ejecutar comandos con la función [`run`](https://docs.python.org/3/library/subprocess.html#subprocess.run). La función recibe como argumento el comando y devuelve un objeto [`CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess). Por defecto, no captura la salida del comando ejecutado, solo el código de retorno (tradicionalmente, se utiliza el 0 para indicar que el proceso ha finalizado con éxito). El siguiente ejemplo ejecuta un comando de listado, `ls`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "# Ejecutamos ls\n",
    "exe_out = sp.run([\"ls\"])\n",
    "\n",
    "# Mostramos el resultado que devuelve run\n",
    "print(exe_out)\n",
    "print(\"The args were: {}\".format(exe_out.args))\n",
    "print(\"The return code was: {}\".format(exe_out.returncode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es un objeto [`CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess) que contiene tanto los argumentos como el código de retorno.\n",
    "\n",
    "Podemos pasar argumentos adicionales añadiendo elementos a la lista que se envía como primer parámetro:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos ls -l\n",
    "sp.run([\"ls\", \"-l\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de recuperar no sólo el código de retorno sino también la salida de la ejecución del comando, usaremos el parámetro `stdout`, que permite indicar a donde enviamos la salida:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos ls -l y capturamos la salida de la ejecución\n",
    "exe_out = sp.run(['ls', '-l'], encoding='utf-8', stdout=sp.PIPE)\n",
    "\n",
    "# Mostramos el resultado que devuelve run\n",
    "print(exe_out)\n",
    "\n",
    "print(\"\\nThe args were: {}\".format(exe_out.args))\n",
    "print(\"\\nThe return code was: {}\".format(exe_out.returncode))\n",
    "print(\"\\nThe output was:\\n{}\".format(exe_out.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, el objeto [`CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess) contiene también un atributo `stdout` con el resultado de la ejecución del proceso que, en este caso, consiste en el listado del directorio donde se ha ejecutado.\n",
    "\n",
    "Podemos utilizar [`run`](https://docs.python.org/3/library/subprocess.html#subprocess.run) también para ejecutar otros programas, que no sean comandos del sistema. Por ejemplo, en la carpeta `files_folder` hay un pequeño script de bash con el siguiente código:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"Script executed!\"\n",
    "```\n",
    "\n",
    "Es decir, el script simplemente muestra por pantalla el mensaje 'Script executed!' cada vez que es ejecutado.\n",
    "\n",
    "**Antes de ejecutar la celda siguiente**, daremos permisos de ejecución al script y probaremos su funcionamiento:\n",
    "\n",
    "1. En primer lugar, abrid una consola del sistema, situaos en la carpeta `files_folder` y ejecutad el siguiente comando:\n",
    "`chmod +x *.sh`\n",
    "\n",
    "Esto dará permisos de ejecución al script, ya que por defecto los archivos no pueden ejecutarse (por cuestiones de seguridad).\n",
    "\n",
    "2. Ahora, desde la misma consola, ejecutad el script:\n",
    "`./echo_script.sh`\n",
    "\n",
    "Esto ejecutará el script y mostrará el mensaje 'Script executed!' en vuestro terminal.\n",
    "\n",
    "Veamos pues como podemos ejecutar este mismo *script* desde nuestro programa Python con [`run`](https://docs.python.org/3/library/subprocess.html#subprocess.run):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos echo_script y capturamos la salida de la ejecución\n",
    "exe_out = sp.run([\"./files_folder/echo_script.sh\"],\n",
    "                 encoding='utf-8', stdout=sp.PIPE)\n",
    "print(exe_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función [`run`](https://docs.python.org/3/library/subprocess.html#subprocess.run) también permite ejecutar un programa externo y pasarle datos de entrada. Por ejemplo, el script `echo_read_script.sh` tiene el siguiente código:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"Enter a number\"\n",
    "read number\n",
    "echo \"Your number was $number\"\n",
    "```\n",
    "\n",
    "Es decir, el script muestra primero el mensaje 'Enter a number', pide al usuario que entre un número, y muestra por pantalla el mensaje 'Your number was' y el número introducido por el usuario.\n",
    "\n",
    "Ejecutamos ahora el script `echo_read_script.sh`, pasándole como entrada el contenido del archivo` a_number.txt` (que contiene el número 42):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos echo_read_script, capturando la salida de la ejecución\n",
    "# y pasando como entrada el contenido del archivo a_number\n",
    "with open(\"files_folder/a_number.txt\", \"r\") as f:\n",
    "    exe_out = sp.run([\"./files_folder/echo_read_script.sh\"],\n",
    "                     encoding='utf-8',\n",
    "                     stdin=f,\n",
    "                     stdout=sp.PIPE)\n",
    "    # Mostramos el resultado que devuelve run\n",
    "    print(exe_out)\n",
    "    print(\"\\nThe args were: {}\".format(exe_out.args))\n",
    "    print(\"The return code was: {}\".format(exe_out.returncode))\n",
    "    print(\"The output was:\\n{}\".format(exe_out.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya para terminar, es importante notar que la función [`run`](https://docs.python.org/3/library/subprocess.html#subprocess.run) ejecuta lo que le hayamos indicado y luego espera (por defecto de manera indefinida) a que finalice la ejecución del comando. Por lo tanto, una llamada a [`run`](https://docs.python.org/3/library/subprocess.html#subprocess.run) puede bloquear nuestro programa si el programa que ejecutamos no acaba nunca. Así, por ejemplo, la ejecución del script `endless_script.sh` con el siguiente código que contiene un bucle infinito:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "while true\n",
    "do\n",
    "\tsleep 1\n",
    "done\n",
    "```\n",
    "\n",
    "haría que nuestro programa Python se quedara indefinidamente esperando. Para evitarlo, [`run`](https://docs.python.org/3/library/subprocess.html#subprocess.run) tiene un parámetro` timeout`, que permite especificar el tiempo máximo (en segundos) que queremos esperar a la ejecución de un programa externo. Pasado este tiempo, si la ejecución no ha finalizado se genera una excepción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos ls con timeout (la ejecución finaliza sin\n",
    "# generar excepción)\n",
    "try:\n",
    "    exe_out = sp.run([\"ls\"], timeout=3)\n",
    "except sp.TimeoutExpired as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos el script endless_script con timeout\n",
    "# (la ejecución finaliza con un timeout a los 3 segundos)\n",
    "try:\n",
    "    exe_out = sp.run([\"./files_folder/endless_script.sh\"],\n",
    "                     timeout=3)\n",
    "except sp.TimeoutExpired as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto pues como la función [`run`](https://docs.python.org/3/library/subprocess.html#subprocess.run) es bastante versátil, y nos permite ejecutar programas externos desde nuestro código Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.- Ejercicios para practicar\n",
    "\n",
    "A continuación encontraréis un conjunto de problemas que os pueden servir para practicar los conceptos explicados en esta unidad. Os recomendamos que intentéis realizar estos problemas vosotros mismos y que, una vez realizados, comparéis la solución que proponemos con vuestra solución. No dudéis en dirigir todas las dudas que surjan de la resolución de estos ejercicios o bien de las soluciones propuestas al foro del aula.\n",
    "\n",
    "1. Cread un código que permita monitorear el consumo de memoria RAM de la máquina en la que se ejecute. El código guardará los datos de la memoria total y utilizada del sistema durante un período de tiempo, capturando los datos en intervalos periódicos.\n",
    "\n",
    "Estos datos se guardarán en archivos de texto, utilizando un fichero para los datos capturados en cada momento. Así, dentro de la carpeta de datos, habrá una carpeta para los datos de cada día (que tendrá por nombre el año, el mes y el día, escritos seguidos, por ejemplo, `20200318`). Dentro de la carpeta de cada día, habrá un archivo para cada instante de tiempo en el que se hayan obtenido datos (que tendrá por nombre la hora, el minuto y el segundo, separados por guiones bajos, por ejemplo, `14_45_55`). El contenido del archivo serán los dos valores (memoria total y utilizada) separados por comas (por ejemplo, `15571, 4242`).\n",
    "\n",
    "Cread también el código que permita recuperar todos los datos almacenados, y obtener una descripción estadística básica (media, mediana y desviación estándar).\n",
    "\n",
    "Para ello, implementaremos una serie de funciones que se detallan a continuación.\n",
    "\n",
    "1.1 Cread una función que reciba como parámetro el nombre de una carpeta (que será `mem_data` por defecto) y cree las carpetas necesarias para almacenar datos para el día actual. Es decir, el código deberá crear, si no existe ya, una carpeta de datos con el nombre que ha recibido como parámetro (o usar `mem_data` si no se ha especificado ningún nombre), y otra carpeta dentro de la misma que tenga por nombre el día actual (en el formato año de 4 cifras, mes de 2 cifras, día de 2 cifras, seguidos sin separadores, por ejemplo, `20200318`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Implementad una función que reciba como parámetro el *path* con la carpeta de la fecha actual (que se ha creado en el apartado anterior) y escriba un fichero con los datos de consumo de memoria del sistema actuales. El archivo debe tener por nombre la hora actual (en el formato `hora_minuto_segundo`, con los ítems separados por guiones bajos, por ejemplo,` 14_45_55`). El contenido del archivo serán los dos valores (memoria total y utilizada) en megabytes separados por comas (por ejemplo, `15571, 4242`).\n",
    "\n",
    "Para obtener los datos del consumo de memoria, recordad que podéis ejecutar comandos del sistema con el módulo `subprocess` (seguramente necesitaréis buscar información sobre cómo obtener estos datos con comandos de *unix*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Implementad una función que reciba como parámetros el número de muestras a capturar y el intervalo de tiempo entre cada una de las muestras (en segundos), y capture los datos del consumo de memoria tantas veces como se haya especificado, esperando el tiempo indicado entre capturas. La función hará uso de las dos funciones definidas anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Llamad a la función definida en el apartado 1.3 y capturad 20 muestras de consumo de memoria, utilizando un intervalo de 3 segundos entre cada captura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Implementad una función que lea todos los datos que se han capturado, almacenados en una carpeta que recibirá como parámetro (y que, de nuevo, tomará como valor por defecto `mem_data`), y muestre los siguientes datos:\n",
    "* El número de muestras leídas.\n",
    "* La media de la memoria total y utilizada.\n",
    "* La mediana de la memoria total y utilizada.\n",
    "* La desviación estándar de la memoria total y utilizada.\n",
    "* La fecha y hora de la primera y última capturas de las que tenemos datos.\n",
    "\n",
    "Llamad a la función anterior para obtener un resumen de los datos capturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 Implementad una función que cree un archivo comprimido con todos los datos almacenados para cada día. La función recibirá como argumento el nombre de la carpeta de datos (por defecto, `mem_data`) y creará tantos ficheros comprimidos como días de los que disponemos datos. Cada archivo comprimido contendrá todos los archivos de datos de ese día.\n",
    "\n",
    "Llamad a la función anterior y compruebad que se generan los ficheros comprimidos correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.- Soluciones a los ejercicios para practicar\n",
    "\n",
    "1. Cread un código que permita monitorear el consumo de memoria RAM de la máquina en la que se ejecute. El código guardará los datos de la memoria total y utilizada del sistema durante un período de tiempo, capturando los datos en intervalos periódicos.\n",
    "\n",
    "Estos datos se guardarán en archivos de texto, utilizando un fichero para los datos capturados en cada momento. Así, dentro de la carpeta de datos, habrá una carpeta para los datos de cada día (que tendrá por nombre el año, el mes y el día, escritos seguidos, por ejemplo, `20200318`). Dentro de la carpeta de cada día, habrá un archivo para cada instante de tiempo en el que se hayan obtenido datos (que tendrá por nombre la hora, el minuto y el segundo, separados por guiones bajos, por ejemplo, `14_45_55`). El contenido del archivo serán los dos valores (memoria total y utilizada) separados por comas (por ejemplo, `15571, 4242`).\n",
    "\n",
    "Cread también el código que permita recuperar todos los datos almacenados, y obtener una descripción estadística básica (media, mediana y desviación estándar).\n",
    "\n",
    "Para ello, implementaremos una serie de funciones que se detallan a continuación.\n",
    "\n",
    "1.1 Cread una función que reciba como parámetro el nombre de una carpeta (que será `mem_data` por defecto) y cree las carpetas necesarias para almacenar datos para el día actual. Es decir, el código deberá crear, si no existe ya, una carpeta de datos con el nombre que ha recibido como parámetro (o usar `mem_data` si no se ha especificado ningún nombre), y otra carpeta dentro de la misma que tenga por nombre el día actual (en el formato año de 4 cifras, mes de 2 cifras, día de 2 cifras, seguidos sin separadores, por ejemplo, `20200318`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def create_folder(data_folder='mem_data'):\n",
    "    today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    full_path = os.path.join(data_folder, today, \"\")\n",
    "    # Creamos tanto la carpeta data_folder como la subcarpeta con el día\n",
    "    # y evitamos obtener errores si ya existen\n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "    return full_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Implementad una función que reciba como parámetro el *path* con la carpeta de la fecha actual (que se ha creado en el apartado anterior) y escriba un fichero con los datos de consumo de memoria del sistema actuales. El archivo debe tener por nombre la hora actual (en el formato `hora_minuto_segundo`, con los ítems separados por guiones bajos, por ejemplo,` 14_45_55`). El contenido del archivo serán los dos valores (memoria total y utilizada) en megabytes separados por comas (por ejemplo, `15571, 4242`).\n",
    "\n",
    "Para obtener los datos del consumo de memoria, recordad que podéis ejecutar comandos del sistema con el módulo `subprocess` (seguramente necesitaréis buscar información sobre cómo obtener estos datos con comandos de *unix*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_current_data(folder_name):\n",
    "    # Construimos el path del fichero a escribir\n",
    "    file_name = datetime.datetime.now().strftime(\"%H_%M_%S\")\n",
    "    full_path = os.path.join(folder_name, file_name)\n",
    "    with open(full_path, 'w') as f:\n",
    "        # Recuperamos los datos de memoria ejecutando free -tm y quedándonos\n",
    "        # únicamente con los datos de memoria RAM (línea 1), y formatamos\n",
    "        # la salida como pide el enunciado (con los valores separados por\n",
    "        # comas)\n",
    "        exe_out = sp.run(['free', '-tm'], encoding='utf-8', stdout=sp.PIPE)\n",
    "        text = \", \".join(exe_out.stdout.split(\"\\n\")[1].split()[1:3])\n",
    "        # Escrivim el resultat al fitxer\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Implementad una función que reciba como parámetros el número de muestras a capturar y el intervalo de tiempo entre cada una de las muestras (en segundos), y capture los datos del consumo de memoria tantas veces como se haya especificado, esperando el tiempo indicado entre capturas. La función hará uso de las dos funciones definidas anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def store_data(num_samples, interval):\n",
    "    full_path = create_folder()\n",
    "    for _ in range(num_samples):\n",
    "        save_current_data(full_path)\n",
    "        time.sleep(interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Llamad a la función definida en el apartado 1.3 y capturad 20 muestras de consumo de memoria, utilizando un intervalo de 3 segundos entre cada captura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(num_samples=20, interval=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Implementad una función que lea todos los datos que se han capturado, almacenados en una carpeta que recibirá como parámetro (y que, de nuevo, tomará como valor por defecto `mem_data`), y muestre los siguientes datos:\n",
    "* El número de muestras leídas.\n",
    "* La media de la memoria total y utilizada.\n",
    "* La mediana de la memoria total y utilizada.\n",
    "* La desviación estándar de la memoria total y utilizada.\n",
    "* La fecha y hora de la primera y última capturas de las que tenemos datos.\n",
    "\n",
    "Llamad a la función anterior para obtener un resumen de los datos capturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_data(data_folder='mem_data'):\n",
    "    # Recuperamos todos los archivos de datos\n",
    "    all_files = glob.glob(data_folder + '/*/*', recursive=True)\n",
    "    # Cargamos los datos de todos los archivos en listas\n",
    "    # (usamos una lista para cada tipo de datos a guardar)\n",
    "    total_mem, used_mem, dts = [], [], []\n",
    "    for file_name in all_files:\n",
    "        with open(file_name) as f:\n",
    "            # Leemos la línea del fichero\n",
    "            line = f.readline()\n",
    "            # Separamos los dos valores (memoria total y memoria utilizada)\n",
    "            t_mem, u_mem = line.split(\",\")\n",
    "            # Añadimos los datos a las listas\n",
    "            total_mem.append(int(t_mem))\n",
    "            used_mem.append(int(u_mem))\n",
    "            # Añadimos también la fecha y hora del fichero a la lista dts\n",
    "            dt = datetime.datetime.strptime(file_name[-17:], \"%Y%m%d/%H_%M_%S\")\n",
    "            dts.append(dt)\n",
    "\n",
    "    # Mostramos el resumen de los datos leídos\n",
    "    print(\"{} samples read\\n\".format(len(total_mem)))\n",
    "    print(\"Total memory:\\t\\t{} (avg), {} (median), {} std\".format(\n",
    "        np.mean(total_mem), np.median(total_mem), np.std(total_mem)))\n",
    "    print(\"Used memory:\\t\\t{} (avg), {} (median), {} std\".format(\n",
    "        np.mean(used_mem), np.median(used_mem), np.std(used_mem)))\n",
    "    print(\"First sample is from:\\t{}\".format(min(dts)))\n",
    "    print(\"Last sample is from:\\t{}\".format(max(dts)))\n",
    "\n",
    "\n",
    "read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 Implementad una función que cree un archivo comprimido con todos los datos almacenados para cada día. La función recibirá como argumento el nombre de la carpeta de datos (por defecto, `mem_data`) y creará tantos ficheros comprimidos como días de los que disponemos datos. Cada archivo comprimido contendrá todos los archivos de datos de ese día.\n",
    "\n",
    "Llamad a la función anterior y compruebad que se generan los ficheros comprimidos correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_data(data_folder='mem_data'):\n",
    "\n",
    "    date_folders = glob.glob(data_folder + '/*')\n",
    "    for date_folder in date_folders:\n",
    "        # Creamos el ficherp .zip\n",
    "        zip_file = os.path.join(date_folder + '.zip')\n",
    "        # Añadimos al fichero .zip todos los ficheros que hay en la carpeta\n",
    "        # date_folder que estamos procesando\n",
    "        with zf.ZipFile(zip_file, 'w', compression=zf.ZIP_DEFLATED) as zip_f:\n",
    "            zip_f.write(date_folder)\n",
    "            sample_files = glob.glob(date_folder + '/*')\n",
    "            for sample_file in sample_files:\n",
    "                zip_f.write(sample_file)\n",
    "\n",
    "\n",
    "compress_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.- Bibliografía\n",
    "\n",
    "\n",
    "## 8.1.- Bibliografía básica\n",
    "\n",
    "La codificación es uno de los detalles importantes a considerar cuando hay que leer y/o escribir un archivo y, a menudo, es el origen de dolores de cabeza en muchos programadores (sobre todo en lenguajes de más bajo nivel que Python). Para entender qué es la codificación de caracteres, conocer cuáles son las codificaciones de caracteres más habituales y saber cómo gestiona Python 3 la codificación, leed ahora la [guía de este enlace](https://realpython.com/python-encodings-guide/#python-3-all-in-on-unicode).\n",
    "\n",
    "\n",
    "## 8.2.- Bibliografía adicional - Ampliación de conocimientos\n",
    "\n",
    "Esta unidad presenta una introducción a cómo interactuar con el sistema de archivos y, en general, con el sistema operativo, desde Python. Así, como introducción, presenta algunas cuestiones de manera inicial y abre la puerta a explorarlas en más profundidad. A continuación se listan algunos enlaces que os servirán para seguir explorando algunos de los temas que trabajamos en la unidad, ya sean puramente de programación en Python como del sistema operativo:\n",
    "\n",
    "* **El sistema de ficheros de Linux**: En la unidad hablamos de interactuar con el sistema de archivos de Linux, pero no entramos a explicar cómo es este sistema de ficheros. Si deseáis leer una introducción a este sistema, este [*Overview*](https://tldp.org/LDP/intro-linux/html/sect_03_01.html) os puede ser muy útil.\n",
    "\n",
    "* **Permisos sobre los ficheros en unix**: Si tenéis curiosidad por saber cómo funcionan los bits de permiso de los ficheros en unix, os recomendamos leer las tres partes de la serie de artículos sobre los permisos ([1](http://www.filepermissions.com/articles/what-are-file-permissions-in-linux-and-mac), [2](http://www.filepermissions.com/articles/understanding-octal-file-permissions ), y [3](http://www.filepermissions.com/articles/sticky-bit-suid-and-sgid)).\n",
    "\n",
    "* **Apertura de archivos desde Python**: La función `open` acepta otros argumentos opcionales que no hemos presentado, y que gestionan detalles como el *buffering* de datos, la codificación, la gestión de los errores, la gestión del salto de línea, etc. El lector interesado puede consultar la [documentación oficial de la función `open`](https://docs.python.org/3/library/functions.html#open) para descubrir cómo funcionan estos argumentos y qué opciones se encuentran disponibles.\n",
    "\n",
    "* **Compresión de archivos**: Existen otros formatos de compresión de datos a parte de los que hemos visto en esta unidad. El lector interesado puede leer la documentación del módulo [`gzip`](https://docs.python.org/3/library/gzip.html) para conocer las funciones que permiten trabajar con archivos gzip desde Python.\n",
    "\n",
    "* **Lectura de ficheros con pandas**: Más allá de los ficheros csv, hay otros formatos que también se utilizan a menudo para intercambiar o guardar datos. Pandas dispone de varias funciones para cargar datos provenientes de los formatos de datos más populares, tales como, json ([`read_json`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html#pandas.read_json)) o excel ([`read_excel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html#pandas.read_excel)).\n",
    "\n",
    "También os recomendamos revisar la documentación oficial de las funciones y clases descritas en esta unidad, que encontraréis enlazadas en cada uno de los apartados que las describen, para conocer qué parámetros permiten ajustar su funcionamiento."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
